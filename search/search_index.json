{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"3DBAG pipeline","text":"<p>This is the repository of the 3DBAG production pipeline, shortly known as <code>3dbag-pipeline</code>. The <code>3dbag-pipeline</code> orchestrates the various steps in order to produce and serve the 3DBAG data. Namely:</p> <ul> <li>source data ingestion and preprocessing,</li> <li>input data preparation, such as tiling,</li> <li>building reconstruction,</li> <li>postprocessing, such as validation, format conversion and tiling,</li> <li>data deployment.</li> </ul> <p>The <code>3dbag-pipeline</code> is built with the Dagster data orchestration tool, therefore some familiarity with Dagster is recommended.</p> <p> Screenshot of the 3dbag-pipeline in the dagster UI.</p> <p>The 3dbag-pipeline is written in Python, because Dagster is a Python framework, however, almost all data processing is done by external tools.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>You will find the complete documentation at https://innovation.3dbag.nl/3dbag-pipeline.</p>"},{"location":"#project-layout","title":"Project layout","text":"<p>The 3dbag-pipeline is organized into several packages. The packages are organized into a <code>common</code> package and a number of workflow packages. The <code>common</code> package contains the resources, functions and type definitions that are used by the 3DBAG packages that define the data processing workflows. The workflow packages contain the assets, jobs, sensors etc. that define a data processing workflow for a part of the complete 3DBAG.</p> <p>The reason for this package organization is that workflow packages have widely different dependencies, and installing them into the same environment bound to lead to dependency conflicts. Additionally, this organization makes it easier to install and test the workflow packages in isolation.</p> <ul> <li><code>common</code>: The common package used by the workflow packages.</li> <li><code>core</code>: Workflow for producing the core of the 3D BAG data set.</li> <li><code>party_walls</code>: Workflow for calculating the party walls.</li> <li><code>floors-estimation</code>: Workflow for estimating the number of floors.</li> </ul>"},{"location":"#deployment","title":"Deployment","text":"<p>Deploying the 3dbag-pipeline is complex, because of its many components and dependencies. You can read about the details on how can you deploy it in the deployment section.</p>"},{"location":"#production","title":"Production","text":""},{"location":"#integration-as-a-library","title":"Integration as a library","text":"<p>The 3dbag-pipeline can be used as a library in other projects. The packages can be installed directly from GitHub using specific release versions. Note that you must use the uv package manager to install the packages, because pip cannot resolve the relative package paths within this repository.</p> <pre><code># Install specific release version of the common package\nuv pip install \"bag3d-common @ git+https://github.com/3DBAG/3dbag-pipeline.git@v2024.12.16#egg=bag3d-common&amp;subdirectory=packages/common\"\n\n# Install specific commit of the common package\nuv pip install \"bag3d-common @ git+https://github.com/3DBAG/3dbag-pipeline.git@&lt;commit-hash&gt;#egg=bag3d-common&amp;subdirectory=packages/common\"\n</code></pre>"},{"location":"#license","title":"License","text":"<p>Licensed under either of</p> <ul> <li>Apache License, Version 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0)</li> <li>MIT license (LICENSE-MIT or http://opensource.org/licenses/MIT)</li> </ul> <p>at your option.</p>"},{"location":"#contribution","title":"Contribution","text":"<p>Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.</p>"},{"location":"#3dbag-organisation","title":"3DBAG organisation","text":"<p>This software is part of the 3DBAG project. For more information visit the 3DBAG organisation.</p>"},{"location":"index_common/","title":"bag3d-common \u2013 common resources, utilities and types for the 3D BAG pipeline","text":"<p>This package contains the resources, functions and type definitions that are used by the 3D BAG packages that define the data processing workflows. Therefore, this package is meant to be a dependency of the workflow packages and does not contain data assets for instance.</p>"},{"location":"index_common/#install-and-use-in-dependent-workflow-package","title":"Install and use in dependent workflow package","text":"<p>Install this <code>bag3d-common</code> package manually in the virtual environment of the workflow package using its relative path:</p> <pre><code>uv add packages/common --editable\n</code></pre> <p>It will appear in the <code>pyproject.toml</code> file of the workflow package as:</p> <pre><code>[tool.uv.sources]\nbag3d-common = { path = \"packages/common\", editable = true }\n</code></pre> <p>For example use the resources in some <code>module.py</code> in the workflow package:</p> <pre><code>from bag3d.common.resources import database\n\ndatabase.db_connection\n</code></pre>"},{"location":"index_common/#documentation","title":"Documentation","text":"<p>The API is documented with Google-style docstrings. The documentation is built with mkdocs.</p> <p>Install the documentation dependencies and view the docs locally:</p> <pre><code>uv run mkdocs serve\n</code></pre> <p>Go to <code>http://127.0.0.1:8000/</code> in your browser.</p>"},{"location":"index_common/#commands","title":"Commands","text":"<ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"index_common/#documentation-layout","title":"Documentation layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"index_common/#license","title":"License","text":"<p>Licensed under Apache License, Version 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0).</p>"},{"location":"index_common/#contribution","title":"Contribution","text":"<p>Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.</p>"},{"location":"index_core/","title":"bag3d-core","text":"<p>Workflow for producing the core 3D BAG data</p>"},{"location":"index_core/#license","title":"License","text":"<p>Licensed under Apache License, Version 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0).</p>"},{"location":"index_core/#contribution","title":"Contribution","text":"<p>Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.</p>"},{"location":"index_floors_estimation/","title":"bag3d-floors-estimation","text":"<p>Workflow for predicting the number of floors, based on Ellie Roy's thesis.</p>"},{"location":"index_floors_estimation/#license","title":"License","text":"<p>Licensed under Apache License, Version 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0).</p>"},{"location":"index_floors_estimation/#contribution","title":"Contribution","text":"<p>Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.</p>"},{"location":"index_party_walls/","title":"bag3d-party-walls","text":"<p>Workflow for calculating the party walls from the 3D BAG</p>"},{"location":"index_party_walls/#license","title":"License","text":"<p>Licensed under Apache License, Version 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0).</p>"},{"location":"index_party_walls/#contribution","title":"Contribution","text":"<p>Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.</p>"},{"location":"production/","title":"Running the pipeline","text":"<p>The following section describes how to run the 3dbag-pipeline to produce the core of 3DBAG, excluding the extension packages (floors_estimation and party_walls). Note that the 3dbag-pipeline is under active development and this section will change in the coming months.</p> <p>Sourcing the inputs and generating the 3DBAG data requires a lot of storage. As an indication, running the whole pipeline for a single AHN tile, with AHN versions 3 and 4, requires about 70GB space and 1-2 hours processing, depending on the machine.</p> <p>The <code>core</code> package consists of several jobs and they need to be executed in a certain order:</p> <ol> <li>ahn_tile_index</li> <li>ahn3</li> <li>ahn4</li> <li>regular_grid_200m, laz_tiles_ahn3_200m, laz_tiles_ahn4_200m assets</li> <li>source_input</li> <li>nl_reconstruct</li> <li>nl_export</li> </ol>"},{"location":"source_datasets/","title":"Source datasets","text":"<p>They are downloaded with the <code>source_input</code> job and they are:</p> <ul> <li>BAG  </li> <li>AHN</li> <li>TOP10NL (xsd|Code Lists)</li> </ul>"},{"location":"source_datasets/#bag","title":"BAG","text":""},{"location":"source_datasets/#definitions","title":"Definitions","text":"<p>BAG (Basisregistratie Adressen en Gebouwen): It contains data on all addresses and buildings in the Netherlands, such as year of construction, surface area, usage and location. The BAG is part of the government system of basic registrations. Municipalities are source holders of the BAG -  they are responsible for collecting it and recording its quality. The BAG dataset is created in accordance with the Official BAG specifications (BAG Catalogus 2018).. </p> <p>LVBAG(De Landelijke Voorziening BAG): Municipalities are responcible for collecting BAG data and them making them centrally available through LVBAG. The Kadaster then manages the LV BAG and makes the data available to various customers. </p> <p>BAG Extract 2.0: It is a periodic extract from the LVBAG, created by the Kadaster. It is distributed in various manners; We are using the free, downloadable version, which gets updated every month (on the 8th). Alternatively, there are daily and monthly extracts with mutations, per municipality or for the whole country, which are accessible through a subscription.</p> <p>Notes</p> <p>Technically, we could keep our BAG database up-to-date by processing monthly mutations, but the mutations are only available through a subscription. Therefore, we need to drop and recreate our BAG tables from the national extract each time we update the data. In fact, this is one of the recommended methods in the Functioneele beschrijving mutatiebestaanded documentation: \"Het actualiseren van de lokaal ingerichte database kan door middel van het maandelijks inladen van een volledig BAG 2.0 Extract of door het verwerken van mutatiebestanden.\"</p> <p>We can reconstruct the BAG input at any give time (Ts) by selecting on <code>begingeldigheid &lt;= Ts &lt;= eindgeldigheid</code>.</p> <p>The <code>oorspronkelijkbouwjaar</code> is not an indicator of a change in the geometry.</p> <p>Some links</p> <p>BAG object history documentation</p> <p>Official BAG specifications (BAG Catalogus 2018)</p> <p>BAG-API GitHub repo</p> <p>Official BAG viewer</p> <p>BAG quality dashboard</p>"},{"location":"source_datasets/#ahn","title":"AHN","text":"<p>The National Height Model of the Netherlands (AHN) is the openly available elevation data set of the Netherlands. This is acquired through airborne laser scanning (LiDAR), with an average point density of 8 points per square meter for the current version.</p> <p>For the 3DBAG we use a smart combination of AHN3, AHN4 and AHN5. AHN4 was acaquired between 2014 and 2019, AHN4 between 2020 and 2022 and AHN5's collection started in 2023 and it is expected to be completed in 2025. Here you can find the collection dates for each region in the Netherlands. Be aware that if a building was constructed or changed on a later date than AHN was collected in that area, it can happen that this building has not been captured in the pointcloud and, subsequently, is not correctly reconstructed or even present in the 3DBAG.</p> <p>For the latest versions of the 3DBAG we use both AHN3 and AHN4 but also recently AHN5 when available. This is to guarantee the best possible 3D reconstruction for each building. If a building has no mutation since the acquisition of AHN3, we pick the pointcloud with the best point coverage. This reduces the odds that a building contains small errors due to large no data gaps in the point cloud.</p> <p>There can always be some variation in the point density between buildings and even within one building. There can be no data gaps in the point cloud, caused by an occlusion through objects, water ponds on roofs and scan angle. The number of available points, their distribution and accurate classification has a very significant impact on the quality of the reconstructed models. The quality attributes that we calculate for and assign to each model provide an indication of this quality.</p>"},{"location":"source_datasets/#top10nl","title":"TOP10NL","text":"<p>The TOP10NL is part of the TOPNL data sets, which belong to the Topographic Register of the Netherlands. The TOP10NL can be used at various scales, ranging from 1:5,000 to 1:25,000. It models several object types, including buildings and their function. The TOPNL data can be used as data source, as well as base maps in visualisations.</p> <p>From the TOP10NL we only use the buildings in order to identify the greenhouses and large warehouses among the BAG objects. Due to their glass roof, greenhouses are problematic for our reconstruction algorithm. Therefore we only model these with a simplified shape.</p>"},{"location":"deployment/","title":"Deployment","text":"<p>Deploying the 3DBAG pipeline is complex due to its many components and dependencies.  Local deployment involves compiling several dependencies from source, ensuring they are correctly linked, installing the 3DBAG pipeline code in virtual environments, configuring the Dagster instance, and optionally setting it up as a service.  We have tested the local setup on Ubuntu 22.04, 24.04 only, and we don't have plans to explore any other operating systems or versions. The required Python versions for the 3dbag-pipeline code are 3.11 for the <code>party_walls</code> package and 3.12 for the other packages. Instead of the local deployment, we highly recommend using Docker for deploying the pipeline.</p>"},{"location":"deployment/#docker","title":"Docker","text":"<p>We provide a sample docker compose file for deploying the 3dbag-pipeline in a multi-container setup. You can read more about the docker-based deployment here.</p>"},{"location":"deployment/#local","title":"Local","text":"<p>In order to deploy the 3DBAG pipeline locally, as a service, you need to make sure that all the required tools are installed. We don't recommend doing this. However, the development setup and the dagster deployment guide can give you some hints on how to deploy the 3dbag-pipeline as a service.</p>"},{"location":"deployment/#resources","title":"Resources","text":"<p>The 3DBAG pipeline is a heavy process that requires a well configured PostgreSQL database. Some instructions for configuring your database can be found here in the following links:</p> <p>Resource Consumption Write Ahead Log WAL Configuration</p> <p>Indicatively, here are some specifications of our database setup:</p> <pre><code>shared_buffers = 24GB\nmax_parallel_workers = 24\nmax_connections = 150\neffective_cache_size = 4GB\neffective_io_concurrency = 100\nmaintenance_work_mem = 2GB\n</code></pre>"},{"location":"deployment/docker/","title":"Docker","text":"<p>The sample docker compose file (<code>docker/compose.yaml</code>) contains a multi-container setup for running the 3dbag-pipeline in a dockerized environment. The setup contains:</p> <ul> <li>multiple dagster services (prefix <code>dagster_</code>), </li> <li>one service for each workflow package (prefix <code>bag3d_</code>), </li> <li>a database for pipeline generated data (prefix <code>data_</code>),</li> <li>external, named volumes that store the data for the pipeline,</li> <li>a network.</li> </ul> <p>The tests that are run on GitHub Actions use this configuration.</p>"},{"location":"deployment/docker/#docker-images","title":"Docker images","text":"<p>The docker images that are built from the <code>develop</code> branch and pushed to DockerHub with a <code>develop</code> tag.</p> <p><code>3dgi/3dbag-pipeline-tools</code></p> <p>The 3dbag-pipeline calls several tools in a subprocess, e.g. roofer, tyler, gdal, pdal etc. We maintain a builder image in <code>docker/tools/Dockerfile</code> with all of these tools installed, and use it as a base image for building the images of the workflow packages (<code>core</code>, <code>floors_estimation</code>, <code>party_walls</code>).</p> <p><code>3dgi/3dbag-pipeline-core</code> </p> <p>Contains the <code>core</code> package, based on <code>3dgi/3dbag-pipeline-tools</code>.  The image contains all build dependencies for installing the python project, so that it is possible to develop the code in a container. The Dockerfile is <code>docker/pipeline/bag3d-core.dockerfile</code>.</p> <p><code>3dgi/3dbag-pipeline-floors-estimation</code> </p> <p>Contains the <code>floors_estimation</code> package, based on <code>3dgi/3dbag-pipeline-tools</code>.  The image contains all build dependencies for installing the python project, so that it is possible to develop the code in a container. The Dockerfile is <code>docker/pipeline/bag3d-floors-estimation.dockerfile</code>.</p> <p><code>3dgi/3dbag-pipeline-party-walls</code></p> <p>Contains the <code>party_walls</code> package, based on <code>3dgi/3dbag-pipeline-tools</code>.  The image contains all build dependencies for installing the python project, so that it is possible to develop the code in a container. The Dockerfile is <code>docker/pipeline/bag3d-party-walls.dockerfile</code>.</p> <p><code>3dgi/3dbag-pipeline-party-dagster</code></p> <p>Image for running the dagster webserver and daemon. The Dockerfile is <code>docker/dagster/Dockerfile</code>.</p>"},{"location":"deployment/docker/#how-to-run-the-services","title":"How to run the services","text":"<p>To run the services in <code>docker/compose.yaml</code>, do the following steps.</p> <p>Download the test data files.</p> <pre><code>make download\n</code></pre> <p>Create the docker volumes and copy the test data file into the volumes.</p> <pre><code>make docker_volume_create\n</code></pre> <p>Build the docker images and start the services.</p> <pre><code>make docker_up\n</code></pre> <p>To only start the postgres database with the test data, run:</p> <pre><code>make docker_up_postgres\n</code></pre> <p>Finally, remove the volumes, containers and images created in previous steps.</p> <pre><code>make docker_down_rm\n</code></pre> <p>Rebuild the images, volumes and restart the services.</p> <pre><code>make docker_restart\n</code></pre>"},{"location":"development/","title":"Development","text":"<p>The following sections describe how to get started with contributing to the 3dbag-pipeline.</p> <ul> <li>For setting up your environment and running the tests please have a look at our code section</li> <li>For information about how to submit a contribution please have a look at our guidelines.</li> <li>For information about how to write documentation for the software, please have a look at the documentation section</li> </ul>"},{"location":"development/code/","title":"Code","text":"<p>Thank you for considering contributing to the 3DBAG pipeline. In this document, we will guide you through setting up your local development environment and running the tests. For information on how to submit a contribution, please refer to our guidelines.</p>"},{"location":"development/code/#setup","title":"Setup","text":"<p>After cloning the repository from https://github.com/3DBAG/3dbag-pipeline, the recommended way to set up your environment is with Docker.</p> <p>Requirements:</p> <ul> <li> <p>Python &gt;=3.11</p> </li> <li> <p>make</p> </li> <li> <p>Docker Engine</p> </li> <li> <p>Docker Compose (&gt;= 2.22.0)</p> </li> </ul> <p>We use <code>make</code> for managing many commands that we use in development.</p>"},{"location":"development/code/#test-data-docker-volumes","title":"Test data &amp; Docker Volumes","text":"<p>The Makefile uses two different .env files for controlling the local environment and the environment in the Docker containers. The <code>.env</code> file in the root directory is used for the local environment and the <code>docker/.env</code> file is used for the Docker environment. The values in the root <code>.env</code> file are specific to your local environment and you need to set them up yourself.</p> <pre><code>echo \"BAG3D_TEST_DATA=${PWD}/tests/test_data\" &gt; .env\n</code></pre> <p>Download test data:</p> <pre><code>make download\n</code></pre> <p>Create the docker volumes that store the test data:</p> <pre><code>make docker_volume_create\n</code></pre> <p>In addition, <code>make docker_volume_rm</code> removes the volumes, <code>make docker_volume_recreate</code> recreates the volumes.</p> <p>Note that if you change the test data locally and you want the docker services to use the updated data, you need to:</p> <ol> <li> <p>stop the services: <code>make docker_down</code></p> </li> <li> <p>recreate the volumes in order to copy the new data into them: <code>make docker_volume_recreate</code></p> </li> <li> <p>start the service again: <code>make docker_up</code></p> </li> </ol>"},{"location":"development/code/#docker-containers","title":"Docker containers","text":"<p>Start the docker containers with <code>watch</code> enabled with the following command:</p> <pre><code>make docker_watch\n</code></pre> <p>The <code>watch</code> attribute allows you to synchronize changes in the code with your containers. When you issue this command for the first time, several things happen:</p> <ol> <li> <p>The required base images are pulled from DockerHub.</p> </li> <li> <p>The 3dbag-pipeline workflow images are built from the local source code.</p> </li> <li> <p>The containers are connected to the volumes and networks.</p> </li> <li> <p>The dagster-webserver is published on <code>localhost:3003</code>.</p> </li> <li> <p>Docker compose starts watching for changes in the source code on the host machine.</p> </li> </ol> <p>The running containers contain all the tools required for a complete run of the 3dbag-pipeline. This means that you can develop and test any part of the code locally.</p> <p>If you make a change in the source code in your code editor, the files are automatically synced into the running containers. You can see your changes in effect after reloading the code location, job, asset or resource in the Dagster UI on <code>localhost:3003</code>.</p> <p>The docker documentation describes in detail how the compose watch functionality works.</p> <p>If you don't want to enable the code synchronization, you can use <code>make docker_up</code> command, which starts the containers without without the  <code>watch</code> attribute.</p> <p>The <code>docker_watch</code> and <code>docker_up</code> targets will set the docker compose project name to <code>bag3d-dev</code>.</p>"},{"location":"development/code/#docker-setup-in-pycharm-professional","title":"Docker setup in PyCharm (professional)","text":"<p>Create run configuration that uses the docker compose file. For example, see the screenshot below.  </p> <p>Start the services by running the configuration from the compose file. For example, see the screenshot below.  </p> <p>Set up the python interpreter in the docker container as the project interpreter, using PyCharm's docker-compose interpreter setup. Note here that you need to use the matching service for the 3dbag-pipeline package.  For example, for working on the <code>core</code> package, you need to configure the <code>bag3d-core</code> service for the python interpreter.</p> <p>To run a specific test, set up a run configuration with the python interpreter in docker and make sure to use the environment variables from the <code>docker/.env</code> file. </p> <p>For further details, see the PyCharm documentation.</p>"},{"location":"development/code/#code-formatting","title":"Code formatting","text":"<p>In you have a local installation of <code>uv</code>, you can format you code with:</p> <pre><code>make format\n</code></pre>"},{"location":"development/code/#tests","title":"Tests","text":"<p>Tests are run separately for each package and they are located in the <code>tests</code> directory of the package. Tests use <code>pytest</code>.</p> <p>Some tests take a long time to execute. These are marked with the <code>@pytest.mark.slow</code> decorator and they will be skipped by default. In order to include the slow tests in the test execution, use the <code>--run-slow</code> command line option.</p> <p>The tests use the sample data that are downloaded as shown above.</p> <p>You can run the fast unit test for all packages with:</p> <pre><code>make test\n</code></pre> <p>For running also the slow tests (which require more time) you can run:</p> <p>```shell  make test_slow  <pre><code>For running the integration tests you can use:\n\n ```shell\nmake test_integration\n</code></pre></p> <p>For running all tests, you can run:</p> <pre><code>make test_all\n</code></pre>"},{"location":"development/code/#installing-requirements-without-the-docker-setup","title":"Installing requirements without the Docker setup","text":"<p>The pipeline has the following requirements:</p> <ul> <li> <p>Python 3.11</p> </li> <li> <p>Docker</p> </li> <li> <p>Tyler</p> </li> <li> <p>Geoflow-roofer</p> </li> <li> <p>LAStools</p> </li> <li> <p>gdal</p> </li> <li> <p>pdal</p> </li> </ul> <p>The <code>build-tools.sh</code> Bash script can help you to build the required tools.  See <code>build-tools.sh --help</code> for usage instructions. Note that you need to run <code>build-tools.sh</code> with <code>bash</code> (not <code>sh</code>), and it can take a  couple of hours to build everything. Requirements for building the tools:</p> <ul> <li>C and C++ compilers (min. GCC 13 or Clang 18)</li> <li>CMake</li> <li>Rust toolchain</li> <li>Git</li> <li>wget</li> <li>libgeos</li> <li>sqlite3</li> <li>libtiff</li> </ul>"},{"location":"development/code/#branches","title":"Branches","text":"<p>The <code>master</code> branch contains stable versions of the 3dbag-pipeline. We use the master branch to produce a 3DBAG version.  After a new 3DBAG is successfully produced, we tag and release the master branch, using the version number of the new 3DBAG, in the form of <code>&lt;year&gt;.&lt;month&gt;.&lt;day&gt;</code>, for example <code>2024.10.24</code>.</p> <p>We use production candidate tags in the form of <code>&lt;year&gt;.&lt;month&gt;-pc&lt;build&gt;</code>, for example <code>2024.10-pc0</code>. Production candidates are versions on the <code>develop</code> branch that are deployed to our production server and tested with a full pipeline run, but with a subset of the input. If a production candidate is successful then it will be used for producing the final 3DBAG.</p> <p>Moving the code onto a <code>production</code> branch helps the collaboration with external contributors. When we move a version onto <code>production</code>, we freeze that version and won't add any new features, only fixes that are required in the production test. At the same time, work can continue on the <code>develop</code> branch, pull requests can be opened and merged.</p> <p>The <code>develop</code> branch is a trunk where the pull requests from the contributors are merged. When a pull request is opened, the following checks are performed in GitHub Actions: - static code analysis, - formatting conformance, - unit testing, - integration testing. Each check must pass for the pull request in order to be approved.</p> <p>When a pull request is merged into the develop branch, the following actions are performed in GitHub Actions: - documentation is built, - the docker images are built and published on DockerHub with the <code>develop</code> tag, - the <code>develop</code> docker images are deployed onto our production server.</p>"},{"location":"development/code/#coding-conventions","title":"Coding Conventions","text":"<p>SQL files are stored in the <code>sqlfiles</code> subpackage, so that the <code>bag3d.common.utils.database.load_sql</code> function can load them.</p> <p>The dependency graph of the 3D BAG packages is strictly <code>common</code>&lt;--workflow packages, thus workflow packages cannot depend on each other. If you find that you need to depend on functionality in another workflow package, move that function to <code>common</code>.</p> <p>Docstrings follow the Google style.  However, dagster is too smart for it's own good and if you describe the return value with the <code>Returns:</code> section, then dagster will only display the text of the <code>Returns:</code> section in the dagster UI. A workaround for this is to include the <code>Returns:</code> heading in the return value description. For example <code>Returns a collection type, storing the...</code></p> <p>Assets are usually some results of computations, therefore their names are nouns, not verbs.</p>"},{"location":"development/code/#release-process","title":"Release process","text":"<p>Release always happens from the <code>master</code> branch, after merging the successful production candidate branch into <code>master</code>. See the branches section for more information.</p> <ol> <li>Update the CHANGELOG.md file with the new version and the changes. It must include the new version number that you are releasing, e.g. <code>## [2024.10.24]</code>.</li> <li>On GitHub, create a new pull request from the current production candidate branch to the <code>master</code> branch and merge it.</li> <li>Manually trigger the release workflow on GitHub Actions. You'll need to input the new version number that you added to the CHANGELOG, e.g. <code>2024.10.24</code>. This will create a new release on GitHub and add the contents of the CHANGELOG to the release notes.</li> <li>The workflow will automatically open a pull request from <code>master</code> to <code>develop</code> to merge back the changes from the release. This is done to keep the <code>develop</code> branch up to date with the latest changes from the <code>master</code> branch. You can merge this pull request after the release is done.</li> </ol>"},{"location":"development/code/#dagster","title":"Dagster","text":""},{"location":"development/code/#terminate-all-in-the-queue","title":"Terminate all in the queue","text":"<p>Needs to be executed in the environment where the Dagster UI and the Dagster-daemon are running. This is currently <code>/opt/dagster/venv</code> on gilfoyle. On gilfoyle, need to source all the environment variables first (<code>/opt/dagster/dagster_home/.env</code>).</p> <p>On gilfyole:</p> <pre><code>su dagster\nexport DAGSTER_HOME=/opt/dagster/dagster_home\nsource DAGSTER_HOME=/opt/dagster/dagster_home/.env\nsource /opt/dagster/venv/bin/activate\n</code></pre> <pre><code>from dagster import DagsterInstance, RunsFilter, DagsterRunStatus\n\ninstance = DagsterInstance.get() # needs your DAGSTER_HOME to be set, DAGSTER_HOME=/opt/dagster/dagster_home on gilfoyle\n\nwhile True:\n    queued_runs = instance.get_runs(limit=100, filters=RunsFilter(statuses=[DagsterRunStatus.QUEUED]))\n    if not queued_runs:\n        break\n    for run in queued_runs:\n        instance.report_run_canceled(run)\n</code></pre>"},{"location":"development/code/#schedules-and-sensors","title":"Schedules and sensors","text":"<p>If you want to enable Dagster Schedules or Sensors for your jobs, start the Dagster Daemon process in the same folder as your <code>workspace.yaml</code> file, but in a different shell or terminal.</p> <p>The <code>$DAGSTER_HOME</code> environment variable must be set to a directory for the daemon to work. Note: using directories within /tmp may cause issues. See Dagster Instance default local behavior for more details.</p> <p>In this repository the <code>$DAGSTER_HOME</code> is in <code>tests/dagster_home</code>.</p> <pre><code>export DAGSTER_HOME=&lt;absolute path to tests/dagster_home&gt;\ndagster-daemon run\n</code></pre> <p>Once your Dagster Daemon is running, you can start turning on schedules and sensors for your jobs.</p>"},{"location":"development/code/#graphql-api","title":"GraphQL API","text":"<p>Dagster has a GraphQL API and it is served alongside the dagster-webserver at <code>/graphql</code> (eg <code>http://localhost:3000/graphql</code>). One can do basically everything that is doable in the Dagster UI. Retrieve data on assets, runs etc., but also launch runs.</p> <p>This query to get the asset materializations metadata and asset dependencies (lineage):</p> <pre><code>{\n  assetNodes(\n    group: {\n      groupName: \"top10nl\"\n      repositoryName: \"__repository__\"\n      repositoryLocationName: \"core_py_311_virtual_env\"\n    }\n    pipeline: {\n      pipelineName: \"source_input\"\n      repositoryName: \"__repository__\"\n      repositoryLocationName: \"core_py_311_virtual_env\"\n    }\n    # assetKeys: { path: [\"top10nl\", \"stage_top10nl_gebouw\"] }\n    loadMaterializations: true\n  ) {\n    assetKey {\n      path\n    }\n    dependencies {\n      asset {\n        assetKey{path}\n      }\n    }\n    assetMaterializations(limit: 1) {\n      runId\n      assetLineage {\n        assetKey {\n          path\n        }\n        partitions\n      }\n      metadataEntries {\n        label\n        description\n        __typename\n        ... on TextMetadataEntry {\n          text\n        }\n        __typename\n        ... on IntMetadataEntry {\n          intValue\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"development/documentation/","title":"Documentation","text":"<p>Thank you for considering to contribute to the 3dbag-pipeline. In this document we describe how can you get set up for writing documentation for the software.</p>"},{"location":"development/documentation/#setup","title":"Setup","text":"<p>Clone the repository from https://github.com/3DBAG/3dbag-pipeline.</p> <p>The documentation is built with mkdocs and several plugins.</p> <p>With a local installation of <code>uv</code>, start the mkdocs server with:</p> <pre><code>uv run mkdocs serve\n</code></pre> <p>Verify that you can see the local documentation on <code>http://127.0.0.1:8000/</code> in your browser.</p>"},{"location":"development/documentation/#documenting-the-package","title":"Documenting the package","text":"<p>The APIs (eg. <code>common</code>) is documented with Google-style docstrings. In order to generate the API documentation for a package, the package must be installed. Solely for documentation purposes, this is best done with <code>pip install --no-deps packages/&lt;package&gt;</code>.</p>"},{"location":"development/guidelines/","title":"Contributing Guidelines","text":"<p>There are many ways to contribute to the 3DBAG pipeline, from bug fixes to performance optimizations, new feature design, and new tests. This guide offers a walkthrough of the general process for proposing and implementing a new feature, as well as some tips for engaging with our community.</p> <p>IMPORTANT: If you have simply found a bug but you do not want to solve it yourself, please report it in detail by creating an issue.</p>"},{"location":"development/guidelines/#contribution-stages","title":"Contribution Stages","text":""},{"location":"development/guidelines/#idea-discussion","title":"Idea Discussion","text":"<p>If you have an idea for a feature or for fixing a bug, start by discussing it with the community on Zulip. This will help flesh out the initial idea, allowing the community to provide early feedback before you move on to writing code.</p> <p>Once the concept is solid, you can start coding.</p>"},{"location":"development/guidelines/#implementation","title":"Implementation","text":"<p>You can start implementing your idea or fix by making a feature branch from the <code>develop</code> branch.</p> <p>The <code>develop</code> branch is where the active development occurs and external contributors should base their work here. See here for more information about our workflow and our branches</p> <p>It is expected that you will provide sufficient documentation and tests for your code. Additionally, your code should be formatted according to the PEP 8 style guide. Please test your implementation thoroughly before opening a PR against the <code>develop</code> branch.</p> <p>Each PR is automatically checked for:</p> <ul> <li>Formatting conformance</li> <li>Unit tests</li> <li>Integration tests</li> </ul> <p>Only PRs that pass all checks will be considered for reviewing and will be eventually merged.</p>"},{"location":"development/guidelines/#refinement","title":"Refinement","text":"<p>Based on internal testing and testing against other new features, your contribution may need adjustments or refinements. You might be asked to improve aspects such as code quality, performance, or compatibility with existing functionality.</p> <p>Once a feature has proven stable on the <code>develop</code> branch, it may be promoted to a production candidate.</p>"},{"location":"development/guidelines/#release","title":"Release:","text":"<p>If the production candidate passes testing in the <code>production</code> branch, it will be merged into <code>master</code> and tagged for release.</p> <p>Congratulations, your contribution is now part of the stable 3DBAG pipeline!</p>"},{"location":"development/guidelines/#additional-notes-for-new-contributors","title":"Additional Notes for New Contributors","text":"<p>Start Small: New contributors are encouraged to start with small issues or bug fixes before proposing larger features. </p> <p>Ask for Help: If you need help or aren\u2019t sure about any steps, don\u2019t hesitate to post a question on Zulip. The community is here to support you!</p> <p>Stay Updated: Follow repository updates to stay informed of any changes to the branching strategy or contribution processes. We are still figuring it out - so this might happen quite often.</p> <p>Documentation: Ensure all new features or changes are well-documented. Good documentation helps future contributors and maintainers understand the intent and functionality of your code. You can find the instructions on how to generate the documentation here.</p> <p>Happy contributing! We appreciate your involvement in the 3DBAG pipeline project.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>bag3d<ul> <li>common<ul> <li>resources<ul> <li>database</li> <li>executables</li> <li>files</li> <li>version</li> <li>wkt</li> </ul> </li> <li>sqlfiles</li> <li>types</li> <li>utils<ul> <li>dagster</li> <li>database</li> <li>files</li> <li>geodata</li> <li>requests</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/bag3d/common/","title":"common","text":""},{"location":"reference/bag3d/common/types/","title":"types","text":"<p>Custom types, custom Dagster types</p>"},{"location":"reference/bag3d/common/types/#bag3d.common.types.ExportResult","title":"<code>ExportResult</code>  <code>dataclass</code>","text":"<p>Result of the tile export with tyler for a single tile.</p> <p>Parameters:</p> Name Type Description Default <code>tile_id</code> <code>str</code> <p>Tile ID</p> required <code>cityjson_path</code> <code>Path</code> <p>Path to the cityjson file</p> required <code>gpkg_path</code> <code>Path</code> <p>Path to the geopackage file</p> required <code>obj_paths</code> <code>Sequence[Path]</code> <p>Paths to the OBJ files</p> required <code>wkt</code> <code>str</code> <p>Tile WKT</p> required Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/types.py</code> <pre><code>@dataclass\nclass ExportResult:\n    \"\"\"Result of the tile export with *tyler* for a single tile.\n\n    Args:\n        tile_id (str): Tile ID\n        cityjson_path (Path): Path to the cityjson file\n        gpkg_path (Path): Path to the geopackage file\n        obj_paths (Sequence[Path]): Paths to the OBJ files\n        wkt (str): Tile WKT\n    \"\"\"\n\n    tile_id: str\n    cityjson_path: Path\n    gpkg_path: Path\n    obj_paths: Sequence[Path]\n    wkt: str\n\n    @property\n    def has_cityjson(self) -&gt; bool:\n        \"\"\"Has an existing CityJSON file\"\"\"\n        return self.cityjson_path is not None and self.cityjson_path.exists()\n\n    @property\n    def has_gpkg(self) -&gt; bool:\n        \"\"\"Has an existing GeoPackage file\"\"\"\n        return self.gpkg_path is not None and self.gpkg_path.exists()\n\n    @property\n    def has_obj(self) -&gt; bool:\n        \"\"\"Has all the OBJ files and they exist\"\"\"\n        return len(self.obj_paths) == 3 and all(p.exists() for p in self.obj_paths)\n\n    def __iter__(self):\n        for key in self.__dir__():\n            if key[:2] != \"__\":\n                yield key, getattr(self, key)\n</code></pre>"},{"location":"reference/bag3d/common/types/#bag3d.common.types.ExportResult.has_cityjson","title":"<code>has_cityjson</code>  <code>property</code>","text":"<p>Has an existing CityJSON file</p>"},{"location":"reference/bag3d/common/types/#bag3d.common.types.ExportResult.has_gpkg","title":"<code>has_gpkg</code>  <code>property</code>","text":"<p>Has an existing GeoPackage file</p>"},{"location":"reference/bag3d/common/types/#bag3d.common.types.ExportResult.has_obj","title":"<code>has_obj</code>  <code>property</code>","text":"<p>Has all the OBJ files and they exist</p>"},{"location":"reference/bag3d/common/resources/","title":"resources","text":""},{"location":"reference/bag3d/common/resources/database/","title":"database","text":""},{"location":"reference/bag3d/common/resources/database/#bag3d.common.resources.database.DatabaseResource","title":"<code>DatabaseResource</code>","text":"<p>               Bases: <code>ConfigurableResource</code></p> <p>Database connection.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/database.py</code> <pre><code>class DatabaseResource(ConfigurableResource):\n    \"\"\"\n    Database connection.\n    \"\"\"\n\n    host: Optional[str] = None\n    user: Optional[str] = None\n    password: Optional[str] = None\n    dbname: Optional[str] = None\n    port: Optional[str] = None\n    other_params: Optional[Permissive()] = None\n\n    def __init__(\n        self,\n        host: Optional[str] = None,\n        user: Optional[str] = None,\n        password: Optional[str] = None,\n        dbname: Optional[str] = None,\n        port: Optional[str] = None,\n        other_params: Optional[Permissive()] = None,\n    ):\n        super().__init__(\n            host=host or \"data-postgresql\",\n            user=user or \"baseregisters_test_user\",\n            password=password or \"baseregisters_test_pswd\",\n            dbname=dbname or \"baseregisters_test\",\n            port=port or \"5432\",\n            other_params=other_params or {\"sslmode\": \"allow\"},\n        )\n        conn = DatabaseConnection(\n            user=self.user,\n            password=self.password,\n            host=self.host,\n            port=self.port,\n            dbname=self.dbname,\n            **self.other_params,\n        )\n        # Create the utility Postgres functions\n        PostgresFunctions(conn)\n\n    @property\n    def connect(self):\n        conn = DatabaseConnection(\n            user=self.user,\n            password=self.password,\n            host=self.host,\n            port=self.port,\n            dbname=self.dbname,\n            **self.other_params,\n        )\n        return conn\n</code></pre>"},{"location":"reference/bag3d/common/resources/executables/","title":"executables","text":""},{"location":"reference/bag3d/common/resources/executables/#bag3d.common.resources.executables.AppImage","title":"<code>AppImage</code>","text":"<p>An application, either as paths of executables, or as a docker image.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/executables.py</code> <pre><code>class AppImage:\n    \"\"\"An application, either as paths of executables, or as a docker image.\"\"\"\n\n    def __init__(\n        self,\n        exes: dict,\n        docker_cfg: DockerConfig = None,\n        with_docker: bool = False,\n        kwargs: dict = None,\n    ):\n        self.logger = get_dagster_logger()\n        self.exes = exes\n        self.with_docker = with_docker\n        self.kwargs = kwargs\n        if self.with_docker:\n            self.docker_client = docker.from_env()\n            try:\n                self.docker_image = self.docker_client.images.get(docker_cfg.image)\n            except ImageNotFound:\n                self.docker_image = self.docker_client.images.pull(docker_cfg.image)\n            self.container_mount_point = Path(docker_cfg.mount_point)\n        else:\n            self.docker_client = None\n            self.docker_image = None\n            self.container_mount_point = None\n\n    def execute(\n        self,\n        exe_name: str,\n        command: str,\n        kwargs: dict = None,\n        local_path: Path = None,\n        silent=False,\n        cwd: str = None,\n    ) -&gt; Tuple[int, str]:\n        \"\"\"Execute a command in a docker container if an image is available, otherwise\n        execute with the local executable.\n\n        Since ``execute`` selects the correct executable, based on the availability of\n        a docker image, you always need to pass an ``exe`` placeholder in the\n        ``command`` string. The ``exe`` will be substituted internally by ``execute``.\n        For instance ``\"{exe} --version\"``, to get the version of an executable.\n\n        If the command needs access to a path, the second placeholder that must be in\n        the ``command`` string is ``local_path``.\n        The ``local_path`` in the command string will be substituted with the\n        ``local_path`` parameter value, if the executable is local.\n        If the command runs in docker, the ``local_path`` in the command string takes\n        the value of the ``container_path``.\n\n        The ``container_path`` is computed from the ``local_path`` parameter and the\n        ``mount_point`` configuration value, such that\n        ``container_path = mount_point / local_path.name``.\n\n        Args:\n            exe_name: Name of the executable to run (as defined in the resource config\n                { \"exes\": { &lt;name&gt;: ...} }). This is because an AppImage can use\n                multiple executables, and you need to select the one that needs to be\n                run.\n            command: The command to be executed. It is formatted with the ``kwargs``\n                and the executable. Therefore, it must contain a placeholder for\n                ``exe``, which is substitued from ``self.exe``.\n            kwargs: Keyword arguments to pass as command parameters.\n            local_path: If ``local_path`` is a directory, then it is mounted on the\n                ``mount_point`` directly. If ``local_path`` is a file, then it is\n                mounted on the ``mount_point`` as\n                ``local_path : mount_point/local_path.name``.\n            silent: If False, send execution messages to the logger, else do not log.\n\n        Returns:\n             The STDOUT and return code from the command execution.\n\n        Examples:\n\n            .. code-block:: python\n\n                # Pass the name of the exe first, then the command, including the\n                # 'exe' placeholder.\n                self.execute(\"ogrinfo\", \"{exe} --version\")\n\n                self.execute(\"ogrinfo\", \"{exe} -so -al {local_path}\",\n                             local_path=Path(\"/tmp/myfile.gml\"))\n        \"\"\"\n        if kwargs:\n            if \"exe\" in kwargs:\n                raise ValueError(\n                    \"Cannot include 'exe' in the kwargs. Pass the exe in \"\n                    \"the 'exe_name' parameter.\"\n                )\n            if \"local_path\" in kwargs:\n                raise ValueError(\n                    \"Cannot include 'local_path' in the kwargs. Pass the \"\n                    \"path in the 'local path' parameter.\"\n                )\n        kwargs_with_exe = deepcopy(kwargs) if kwargs else dict()\n        kwargs_with_exe[\"exe\"] = self.exes[exe_name]\n        if self.with_docker:\n            if local_path:\n                if local_path.is_dir():\n                    container_path = self.container_mount_point\n                else:\n                    container_path = self.container_mount_point / local_path.name\n                kwargs_with_exe[\"local_path\"] = container_path\n                volumes = [\n                    f\"{local_path}:{container_path}\",\n                ]\n            else:\n                volumes = None\n            output = self._docker_run(\n                command.format(**kwargs_with_exe), volumes=volumes\n            )\n            return_code = 1 if \"error\" in output.lower() else 0\n        else:\n            kwargs_with_exe[\"local_path\"] = local_path\n            if silent:\n                output, return_code = execute_shell_command_silent(\n                    shell_command=command.format(**kwargs_with_exe), cwd=cwd\n                )\n            else:\n                output, return_code = execute_shell_command(\n                    shell_command=command.format(**kwargs_with_exe),\n                    log=self.logger,\n                    output_logging=\"STREAM\",\n                    cwd=cwd,\n                )\n        if return_code != 0:\n            raise Failure(f\"{kwargs_with_exe['exe']} failed with output:\\n{output}\")\n        elif \"error\" in output.lower():\n            self.logger.error(f\"Error in subprocess output: {output}\")\n            return return_code, output\n        else:\n            return return_code, output\n\n    def _docker_run(self, command, volumes=None, silent=False) -&gt; str:\n        \"\"\"Executes a `command` with 'docker run'.\n\n        The `host_path` is mounted at `mount_point` that is provided in the resource\n            configuration.\n        The `--network` is set to `host`.\n        Removes the container when finished.\n\n        Returns the STDOUT from the container.\n        \"\"\"\n        if self.with_docker:\n            if not silent:\n                logger = get_dagster_logger()\n                logger.info(f\"Executing `{command}` in {self.docker_image.tags}\")\n            stdout = self.docker_client.containers.run(\n                self.docker_image,\n                command=command,\n                volumes=volumes,\n                network_mode=\"host\",\n                remove=True,\n                detach=False,\n                stdout=True,\n                stderr=True,\n            )\n            return stdout.decode(\"utf-8\")\n        else:\n            raise RuntimeError(\n                \"executable resource was not initialized with a docker image\"\n            )\n\n    def version(self, exe: str):\n        version, returncode = execute_shell_command_silent(f\"{exe} --version\")\n        return format_version_stdout(version)\n</code></pre>"},{"location":"reference/bag3d/common/resources/executables/#bag3d.common.resources.executables.AppImage.execute","title":"<code>execute(exe_name, command, kwargs=None, local_path=None, silent=False, cwd=None)</code>","text":"<p>Execute a command in a docker container if an image is available, otherwise execute with the local executable.</p> <p>Since <code>execute</code> selects the correct executable, based on the availability of a docker image, you always need to pass an <code>exe</code> placeholder in the <code>command</code> string. The <code>exe</code> will be substituted internally by <code>execute</code>. For instance <code>\"{exe} --version\"</code>, to get the version of an executable.</p> <p>If the command needs access to a path, the second placeholder that must be in the <code>command</code> string is <code>local_path</code>. The <code>local_path</code> in the command string will be substituted with the <code>local_path</code> parameter value, if the executable is local. If the command runs in docker, the <code>local_path</code> in the command string takes the value of the <code>container_path</code>.</p> <p>The <code>container_path</code> is computed from the <code>local_path</code> parameter and the <code>mount_point</code> configuration value, such that <code>container_path = mount_point / local_path.name</code>.</p> <p>Parameters:</p> Name Type Description Default <code>exe_name</code> <code>str</code> <p>Name of the executable to run (as defined in the resource config { \"exes\": { : ...} }). This is because an AppImage can use multiple executables, and you need to select the one that needs to be run. required <code>command</code> <code>str</code> <p>The command to be executed. It is formatted with the <code>kwargs</code> and the executable. Therefore, it must contain a placeholder for <code>exe</code>, which is substitued from <code>self.exe</code>.</p> required <code>kwargs</code> <code>dict</code> <p>Keyword arguments to pass as command parameters.</p> <code>None</code> <code>local_path</code> <code>Path</code> <p>If <code>local_path</code> is a directory, then it is mounted on the <code>mount_point</code> directly. If <code>local_path</code> is a file, then it is mounted on the <code>mount_point</code> as <code>local_path : mount_point/local_path.name</code>.</p> <code>None</code> <code>silent</code> <p>If False, send execution messages to the logger, else do not log.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[int, str]</code> <p>The STDOUT and return code from the command execution.</p> <p>Examples:</p> <pre><code>.. code-block:: python\n\n    # Pass the name of the exe first, then the command, including the\n    # 'exe' placeholder.\n    self.execute(\"ogrinfo\", \"{exe} --version\")\n\n    self.execute(\"ogrinfo\", \"{exe} -so -al {local_path}\",\n                 local_path=Path(\"/tmp/myfile.gml\"))\n</code></pre> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/executables.py</code> <pre><code>def execute(\n    self,\n    exe_name: str,\n    command: str,\n    kwargs: dict = None,\n    local_path: Path = None,\n    silent=False,\n    cwd: str = None,\n) -&gt; Tuple[int, str]:\n    \"\"\"Execute a command in a docker container if an image is available, otherwise\n    execute with the local executable.\n\n    Since ``execute`` selects the correct executable, based on the availability of\n    a docker image, you always need to pass an ``exe`` placeholder in the\n    ``command`` string. The ``exe`` will be substituted internally by ``execute``.\n    For instance ``\"{exe} --version\"``, to get the version of an executable.\n\n    If the command needs access to a path, the second placeholder that must be in\n    the ``command`` string is ``local_path``.\n    The ``local_path`` in the command string will be substituted with the\n    ``local_path`` parameter value, if the executable is local.\n    If the command runs in docker, the ``local_path`` in the command string takes\n    the value of the ``container_path``.\n\n    The ``container_path`` is computed from the ``local_path`` parameter and the\n    ``mount_point`` configuration value, such that\n    ``container_path = mount_point / local_path.name``.\n\n    Args:\n        exe_name: Name of the executable to run (as defined in the resource config\n            { \"exes\": { &lt;name&gt;: ...} }). This is because an AppImage can use\n            multiple executables, and you need to select the one that needs to be\n            run.\n        command: The command to be executed. It is formatted with the ``kwargs``\n            and the executable. Therefore, it must contain a placeholder for\n            ``exe``, which is substitued from ``self.exe``.\n        kwargs: Keyword arguments to pass as command parameters.\n        local_path: If ``local_path`` is a directory, then it is mounted on the\n            ``mount_point`` directly. If ``local_path`` is a file, then it is\n            mounted on the ``mount_point`` as\n            ``local_path : mount_point/local_path.name``.\n        silent: If False, send execution messages to the logger, else do not log.\n\n    Returns:\n         The STDOUT and return code from the command execution.\n\n    Examples:\n\n        .. code-block:: python\n\n            # Pass the name of the exe first, then the command, including the\n            # 'exe' placeholder.\n            self.execute(\"ogrinfo\", \"{exe} --version\")\n\n            self.execute(\"ogrinfo\", \"{exe} -so -al {local_path}\",\n                         local_path=Path(\"/tmp/myfile.gml\"))\n    \"\"\"\n    if kwargs:\n        if \"exe\" in kwargs:\n            raise ValueError(\n                \"Cannot include 'exe' in the kwargs. Pass the exe in \"\n                \"the 'exe_name' parameter.\"\n            )\n        if \"local_path\" in kwargs:\n            raise ValueError(\n                \"Cannot include 'local_path' in the kwargs. Pass the \"\n                \"path in the 'local path' parameter.\"\n            )\n    kwargs_with_exe = deepcopy(kwargs) if kwargs else dict()\n    kwargs_with_exe[\"exe\"] = self.exes[exe_name]\n    if self.with_docker:\n        if local_path:\n            if local_path.is_dir():\n                container_path = self.container_mount_point\n            else:\n                container_path = self.container_mount_point / local_path.name\n            kwargs_with_exe[\"local_path\"] = container_path\n            volumes = [\n                f\"{local_path}:{container_path}\",\n            ]\n        else:\n            volumes = None\n        output = self._docker_run(\n            command.format(**kwargs_with_exe), volumes=volumes\n        )\n        return_code = 1 if \"error\" in output.lower() else 0\n    else:\n        kwargs_with_exe[\"local_path\"] = local_path\n        if silent:\n            output, return_code = execute_shell_command_silent(\n                shell_command=command.format(**kwargs_with_exe), cwd=cwd\n            )\n        else:\n            output, return_code = execute_shell_command(\n                shell_command=command.format(**kwargs_with_exe),\n                log=self.logger,\n                output_logging=\"STREAM\",\n                cwd=cwd,\n            )\n    if return_code != 0:\n        raise Failure(f\"{kwargs_with_exe['exe']} failed with output:\\n{output}\")\n    elif \"error\" in output.lower():\n        self.logger.error(f\"Error in subprocess output: {output}\")\n        return return_code, output\n    else:\n        return return_code, output\n</code></pre>"},{"location":"reference/bag3d/common/resources/executables/#bag3d.common.resources.executables.GDALResource","title":"<code>GDALResource</code>","text":"<p>               Bases: <code>ConfigurableResource</code></p> <p>A GDAL Resource can be configured by either the local EXE paths for <code>ogr2ogr</code>, <code>ogrinfo</code> and <code>sozip</code>, or by providing the DockerConfig for the GDAL image.</p> <p>For the local exes you can use:</p> <pre><code>gdal_resource = GDALResource(exe_ogr2ogr=os.getenv(\"EXE_PATH_OGR2OGR\"),\n                             exe_ogrinfo=os.getenv(\"EXE_PATH_OGRINFO\"),\n                             exe_sozip=os.getenv(\"EXE_PATH_SOZIP\"))\n</code></pre> <p>For the docker image you can use:</p> <pre><code>gdal_local = GDALResource(docker_cfg=DockerConfig(\n                        image=DOCKER_GDAL_IMAGE,\n                        mount_point=\"/tmp\"))\n</code></pre> <p>If instantiated with GDALResource() then the Docker image is used by default. After the resource has been instantiated, gdal (AppImage) can be acquired with the <code>app</code> property:</p> <pre><code>gdal_resource.app\n</code></pre> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/executables.py</code> <pre><code>class GDALResource(ConfigurableResource):\n    \"\"\"\n    A GDAL Resource can be configured by either the local EXE paths\n    for `ogr2ogr`, `ogrinfo` and `sozip`, or by providing the DockerConfig\n    for the GDAL image.\n\n    For the local exes you can use:\n\n        gdal_resource = GDALResource(exe_ogr2ogr=os.getenv(\"EXE_PATH_OGR2OGR\"),\n                                     exe_ogrinfo=os.getenv(\"EXE_PATH_OGRINFO\"),\n                                     exe_sozip=os.getenv(\"EXE_PATH_SOZIP\"))\n\n    For the docker image you can use:\n\n        gdal_local = GDALResource(docker_cfg=DockerConfig(\n                                image=DOCKER_GDAL_IMAGE,\n                                mount_point=\"/tmp\"))\n\n    If instantiated with GDALResource() then the Docker image is used by\n    default. After the resource has been instantiated, gdal (AppImage) can\n    be acquired with the `app` property:\n\n        gdal_resource.app\n    \"\"\"\n\n    exe_ogrinfo: Optional[str] = None\n    exe_ogr2ogr: Optional[str] = None\n    exe_sozip: Optional[str] = None\n    docker_cfg: Optional[DockerConfig] = None\n\n    @property\n    def exes(self) -&gt; Dict[str, str]:\n        if self.docker_cfg is None:\n            return {\n                \"ogrinfo\": self.exe_ogrinfo,\n                \"ogr2ogr\": self.exe_ogr2ogr,\n                \"sozip\": self.exe_sozip,\n            }\n        else:\n            return {\n                \"ogrinfo\": \"ogrinfo\",\n                \"ogr2ogr\": \"ogr2ogr\",\n                \"sozip\": \"sozip\",\n            }\n\n    @property\n    def with_docker(self) -&gt; bool:\n        if (\n            self.exe_ogrinfo is None\n            and self.exe_ogr2ogr is None\n            and self.exe_sozip is None\n        ):\n            return True\n        else:\n            return False\n\n    @property\n    def app(self) -&gt; AppImage:\n        return AppImage(\n            exes=self.exes, docker_cfg=self.docker_cfg, with_docker=self.with_docker\n        )\n</code></pre>"},{"location":"reference/bag3d/common/resources/executables/#bag3d.common.resources.executables.GeoflowResource","title":"<code>GeoflowResource</code>","text":"<p>               Bases: <code>ConfigurableResource</code></p> <p>A GeoflowResource can be configured by providing the paths to Geoflow <code>exe_geoflow</code> executable on the local system and the path to the reconstruction flowchart.</p> <p>Example:</p> <pre><code>geoflow_resource = GeoflowResource(exe_geoflow = os.getenv(\"EXE_PATH_ROOFER_RECONSTRUCT\"),\n                                   flowchart=os.getenv(\"FLOWCHART_PATH_RECONSTRUCT\"))\n</code></pre> <p>After the resource has been instantiated, geoflow (AppImage) can be acquired with the <code>app</code> property:</p> <pre><code>geoflow = geoflow_resource.app\n</code></pre> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/executables.py</code> <pre><code>class GeoflowResource(ConfigurableResource):\n    \"\"\"\n    A GeoflowResource can be configured by providing the paths to\n    Geoflow `exe_geoflow` executable on the local system\n    and the path to the reconstruction flowchart.\n\n    Example:\n\n        geoflow_resource = GeoflowResource(exe_geoflow = os.getenv(\"EXE_PATH_ROOFER_RECONSTRUCT\"),\n                                           flowchart=os.getenv(\"FLOWCHART_PATH_RECONSTRUCT\"))\n\n    After the resource has been instantiated, geoflow (AppImage) can\n    be acquired with the `app` property:\n\n        geoflow = geoflow_resource.app\n    \"\"\"\n\n    exe_geoflow: Optional[str] = None\n    flowchart: Optional[str] = None\n\n    @property\n    def exes(self) -&gt; Dict[str, str]:\n        return {\"geof\": self.exe_geoflow}\n\n    @property\n    def with_docker(self) -&gt; bool:\n        return False\n\n    @property\n    def app(self) -&gt; AppImage:\n        return AppImage(\n            exes=self.exes,\n            with_docker=self.with_docker,\n            kwargs={\"flowcharts\": {\"reconstruct\": self.flowchart}},\n        )\n</code></pre>"},{"location":"reference/bag3d/common/resources/executables/#bag3d.common.resources.executables.LASToolsResource","title":"<code>LASToolsResource</code>","text":"<p>               Bases: <code>ConfigurableResource</code></p> <p>A LASTools Resource can be configured by providing the paths to LASTools executables \"lasindex\" and \"las2las\" on the local system.</p> <p>Example:</p> <pre><code>lastools_resource = LASToolsResource(exe_lasindex=os.getenv(\"EXE_PATH_LASINDEX\"),\n                                     exe_las2las=s.getenv(\"EXE_PATH_LAS2LAS\"))\n</code></pre> <p>After the resource has been instantiated, lastools (AppImage) can be acquired with the <code>app</code> property:</p> <pre><code>lastools_resource.app\n</code></pre> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/executables.py</code> <pre><code>class LASToolsResource(ConfigurableResource):\n    \"\"\"\n    A LASTools Resource can be configured by providing the paths to\n    LASTools executables \"lasindex\" and \"las2las\" on the local system.\n\n    Example:\n\n        lastools_resource = LASToolsResource(exe_lasindex=os.getenv(\"EXE_PATH_LASINDEX\"),\n                                             exe_las2las=s.getenv(\"EXE_PATH_LAS2LAS\"))\n\n    After the resource has been instantiated, lastools (AppImage) can\n    be acquired with the `app` property:\n\n        lastools_resource.app\n    \"\"\"\n\n    exe_lasindex: Optional[str] = None\n    exe_las2las: Optional[str] = None\n\n    @property\n    def exes(self) -&gt; Dict[str, str]:\n        return {\"lasindex\": self.exe_lasindex, \"las2las\": self.exe_las2las}\n\n    @property\n    def with_docker(self) -&gt; bool:\n        return False\n\n    @property\n    def app(self) -&gt; AppImage:\n        return AppImage(exes=self.exes, with_docker=self.with_docker)\n</code></pre>"},{"location":"reference/bag3d/common/resources/executables/#bag3d.common.resources.executables.PDALResource","title":"<code>PDALResource</code>","text":"<p>               Bases: <code>ConfigurableResource</code></p> <p>A PDAL Resource can be configured by either the local EXE path for <code>pdal</code> or by providing the DockerConfig for the PDAL image.</p> <p>For the local exe you can use:</p> <pre><code>pdal_resource = PDALResource(exe_pdal=os.getenv(\"EXE_PATH_PDAL\"))\n</code></pre> <p>For the docker image you can use:</p> <pre><code>pdal_resource = PDALResource(docker_cfg=DockerConfig(\n                                image=DOCKER_PDAL_IMAGE,\n                                mount_point=\"/tmp\"))\n</code></pre> <p>If instantiated with PDALResource() then the Docker image is used by default. After the resource has been instantiated, pdal (AppImage) can be acquired with the <code>app</code> property:</p> <pre><code>pdal_resource.app\n</code></pre> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/executables.py</code> <pre><code>class PDALResource(ConfigurableResource):\n    \"\"\"\n    A PDAL Resource can be configured by either the local EXE path\n    for `pdal` or by providing the DockerConfig for the PDAL image.\n\n    For the local exe you can use:\n\n        pdal_resource = PDALResource(exe_pdal=os.getenv(\"EXE_PATH_PDAL\"))\n\n    For the docker image you can use:\n\n        pdal_resource = PDALResource(docker_cfg=DockerConfig(\n                                        image=DOCKER_PDAL_IMAGE,\n                                        mount_point=\"/tmp\"))\n\n    If instantiated with PDALResource() then the Docker image is used by\n    default. After the resource has been instantiated, pdal (AppImage) can\n    be acquired with the `app` property:\n\n        pdal_resource.app\n    \"\"\"\n\n    exe_pdal: Optional[str] = None\n    docker_cfg: Optional[DockerConfig] = None\n\n    @property\n    def exes(self) -&gt; Dict[str, str]:\n        if self.docker_cfg is None:\n            return {\n                \"pdal\": self.exe_pdal,\n            }\n        else:\n            return {\n                \"pdal\": \"pdal\",\n            }\n\n    @property\n    def with_docker(self) -&gt; bool:\n        if self.exe_pdal == \"pdal\":\n            return True\n        else:\n            return False\n\n    @property\n    def app(self) -&gt; AppImage:\n        return AppImage(\n            exes=self.exes, docker_cfg=self.docker_cfg, with_docker=self.with_docker\n        )\n</code></pre>"},{"location":"reference/bag3d/common/resources/executables/#bag3d.common.resources.executables.RooferResource","title":"<code>RooferResource</code>","text":"<p>               Bases: <code>ConfigurableResource</code></p> <p>A RooferResource can be configured by providing the paths to Roofer <code>crop</code> and <code>roofer</code> executables on the local system.</p> <p>Example:</p> <pre><code>roofer_resource = RooferResource(exe_crop=os.getenv(\"EXE_PATH_ROOFER_CROP\"),\n                                 exe_roofer=os.getenv(\"EXE_PATH_ROOFER_ROOFER\"))\n</code></pre> <p>After the resource has been instantiated, roofer (AppImage) can be acquired with the <code>app</code> property:</p> <pre><code>roofer = roofer_resource.app\n</code></pre> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/executables.py</code> <pre><code>class RooferResource(ConfigurableResource):\n    \"\"\"\n    A RooferResource can be configured by providing the paths to\n    Roofer `crop` and `roofer` executables on the local system.\n\n    Example:\n\n        roofer_resource = RooferResource(exe_crop=os.getenv(\"EXE_PATH_ROOFER_CROP\"),\n                                         exe_roofer=os.getenv(\"EXE_PATH_ROOFER_ROOFER\"))\n\n    After the resource has been instantiated, roofer (AppImage) can\n    be acquired with the `app` property:\n\n        roofer = roofer_resource.app\n    \"\"\"\n\n    exe_crop: Optional[str] = None\n    exe_roofer: Optional[str] = None\n\n    @property\n    def exes(self) -&gt; Dict[str, str]:\n        return {\n            \"crop\": self.exe_crop,\n            \"roofer\": self.exe_roofer,\n        }\n\n    @property\n    def with_docker(self) -&gt; bool:\n        return False\n\n    @property\n    def app(self) -&gt; AppImage:\n        return AppImage(exes=self.exes, with_docker=self.with_docker)\n</code></pre>"},{"location":"reference/bag3d/common/resources/executables/#bag3d.common.resources.executables.TylerResource","title":"<code>TylerResource</code>","text":"<p>               Bases: <code>ConfigurableResource</code></p> <p>A Tyler Resource can be configured by providing the paths to Tyler executables \"tyler\" and \"tyler-db\" on the local system.</p> <p>Example:</p> <pre><code>tyler_resource = TylerResource(exe_tyler=os.getenv(\"EXE_PATH_TYLER\"),\n                               exe_tyler_db=s.getenv(\"EXE_PATH_TYLER_DB\"))\n</code></pre> <p>After the resource has been instantiated, tyler (AppImage) can be acquired with the <code>app</code> property:</p> <pre><code>tyler = tyler_resource.app\n</code></pre> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/executables.py</code> <pre><code>class TylerResource(ConfigurableResource):\n    \"\"\"\n    A Tyler Resource can be configured by providing the paths to\n    Tyler executables \"tyler\" and \"tyler-db\" on the local system.\n\n    Example:\n\n        tyler_resource = TylerResource(exe_tyler=os.getenv(\"EXE_PATH_TYLER\"),\n                                       exe_tyler_db=s.getenv(\"EXE_PATH_TYLER_DB\"))\n\n    After the resource has been instantiated, tyler (AppImage) can\n    be acquired with the `app` property:\n\n        tyler = tyler_resource.app\n    \"\"\"\n\n    exe_tyler: Optional[str] = None\n    exe_tyler_db: Optional[str] = None\n\n    @property\n    def exes(self) -&gt; Dict[str, str]:\n        return {\"tyler\": self.exe_tyler, \"tyler-db\": self.exe_tyler_db}\n\n    @property\n    def with_docker(self) -&gt; bool:\n        return False\n\n    @property\n    def app(self) -&gt; AppImage:\n        return AppImage(exes=self.exes, with_docker=self.with_docker)\n</code></pre>"},{"location":"reference/bag3d/common/resources/executables/#bag3d.common.resources.executables.execute_shell_command_silent","title":"<code>execute_shell_command_silent(shell_command, cwd=None, env=None)</code>","text":"<p>Execute a shell command without sending the output to the logger, and without writing the command to a script file first.</p> <p>NOTE: This function is based on the execute_script_file dagster_shell function, which can be found here: https://github.com/dagster-io/dagster/blob/master/python_modules/libraries/dagster-shell/dagster_shell/utils.py</p> <p>Parameters:</p> Name Type Description Default <code>shell_command</code> <code>str</code> <p>The shell script to execute.</p> required <code>cwd</code> <code>str</code> <p>Working directory for the shell command to use.</p> <code>None</code> <code>env</code> <code>Dict[str, str]</code> <p>Environment dictionary to pass to <code>subprocess.Popen</code>. Unused by default.</p> <code>None</code> <p>Returns:</p> Type Description <p>Tuple[str, int]: A tuple where the first element is the combined</p> <p>stdout/stderr output of running the shell command and the second element is</p> <p>the return code.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/executables.py</code> <pre><code>def execute_shell_command_silent(shell_command: str, cwd=None, env=None):\n    \"\"\"Execute a shell command without sending the output to the logger, and without\n    writing the command to a script file first.\n\n    NOTE: This function is based on the execute_script_file dagster_shell function,\n    which can be found here: https://github.com/dagster-io/dagster/blob/master/python_modules/libraries/dagster-shell/dagster_shell/utils.py\n\n    Args:\n        shell_command (str): The shell script to execute.\n        cwd (str, optional): Working directory for the shell command to use.\n        env (Dict[str, str], optional): Environment dictionary to pass to ``subprocess.Popen``.\n            Unused by default.\n\n    Returns:\n        Tuple[str, int]: A tuple where the first element is the combined\n        stdout/stderr output of running the shell command and the second element is\n        the return code.\n    \"\"\"\n\n    def pre_exec():\n        # Restore default signal disposition and invoke setsid\n        for sig in (\"SIGPIPE\", \"SIGXFZ\", \"SIGXFSZ\"):\n            if hasattr(signal, sig):\n                signal.signal(getattr(signal, sig), signal.SIG_DFL)\n        os.setsid()\n\n    sub_process = None\n    try:\n        stdout_pipe = PIPE\n        stderr_pipe = STDOUT\n\n        sub_process = Popen(\n            shell_command,\n            shell=True,\n            stdout=stdout_pipe,\n            stderr=stderr_pipe,\n            cwd=cwd,\n            env=env,\n            preexec_fn=pre_exec,\n            encoding=\"UTF-8\",\n        )\n\n        # Stream back logs as they are emitted\n        lines = []\n        for line in sub_process.stdout:\n            lines.append(line)\n        output = \"\".join(lines)\n\n        sub_process.wait()\n\n        return output, sub_process.returncode\n    finally:\n        # Always terminate subprocess, including in cases where the run is terminated\n        if sub_process:\n            sub_process.terminate()\n</code></pre>"},{"location":"reference/bag3d/common/resources/files/","title":"files","text":""},{"location":"reference/bag3d/common/resources/files/#bag3d.common.resources.files.FileStore","title":"<code>FileStore</code>","text":"Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/files.py</code> <pre><code>class FileStore:\n    # TODO: should have a unified interface regardless if we use a volume or local dir\n    def __init__(\n        self,\n        data_dir: Union[str, Path, None] = None,\n        docker_volume_id: Union[str, None] = None,\n        dir_id: Union[str, None] = None,\n    ):\n        self.data_dir = None\n        self.docker_volume = None\n        if data_dir:\n            directory = Path(data_dir)\n            p = directory.resolve()\n            if p.is_dir():\n                pass\n                # # Need r+w for others, so that docker containers can write to the\n                # # directory\n                # if oct(p.stat().st_mode) != \"0o40777\":\n                #     raise PermissionError(f\"Need mode=777 on {p}, because docker \"\n                #                           f\"containers need read+write+execute on it.\")\n            else:\n                p.mkdir()\n                p.chmod(mode=0o777)\n                logger.info(f\"Created directory {p}\")\n            self.data_dir = p\n        elif docker_volume_id:\n            docker_client = docker.from_env()\n            self.docker_volume = None\n            try:\n                self.docker_volume = docker_client.volumes.get(docker_volume_id)\n                logger.info(f\"Using existing docker volume: {docker_volume_id}\")\n            except NotFound:\n                self.docker_volume = docker_client.volumes.create(\n                    name=docker_volume_id, driver=\"local\"\n                )\n                logger.info(f\"Created docker volume: {docker_volume_id}\")\n        else:\n            # In case dir_id is also None, we create a temp dir with a random ID.\n            tmp = self.mkdir_temp(dir_id)\n            self.data_dir = tmp\n            logger.info(f\"Created local temporary directory {self.data_dir}\")\n\n    def rm(self, force=False):\n        if self.data_dir:\n            if force:\n                rmtree(str(self.data_dir))\n            else:\n                self.data_dir.rmdir()\n            logger.info(f\"Deleted directory {self.data_dir}\")\n            self.data_dir = None\n        if self.docker_volume:\n            self.docker_volume.remove(force=force)\n            logger.info(f\"Deleted docker volume {self.docker_volume}\")\n            self.docker_volume = None\n\n    @staticmethod\n    def mkdir_temp(temp_dir_id: str = None) -&gt; Path:\n        \"\"\"Create a temporary directory with the required permissions.\n\n        The path of the new directory is `/tmp/tmp_3dbag_&lt;temp_dir_id&gt;`.\n\n        Args:\n            temp_dir_id (str): The ID-part of the directory name. E.g. the first 8\n                characters of the dagster run ID. If None, a random ID is generated.\n        \"\"\"\n        if temp_dir_id:\n            dir_id = temp_dir_id\n        else:\n            dir_id = \"\".join(random.choice(string.ascii_letters) for _ in range(8))\n        tmp = Path(make_temp_path(dir_id))\n        tmp.mkdir(exist_ok=True)\n        tmp.chmod(mode=0o777)\n        return tmp\n</code></pre>"},{"location":"reference/bag3d/common/resources/files/#bag3d.common.resources.files.FileStore.mkdir_temp","title":"<code>mkdir_temp(temp_dir_id=None)</code>  <code>staticmethod</code>","text":"<p>Create a temporary directory with the required permissions.</p> <p>The path of the new directory is <code>/tmp/tmp_3dbag_&lt;temp_dir_id&gt;</code>.</p> <p>Parameters:</p> Name Type Description Default <code>temp_dir_id</code> <code>str</code> <p>The ID-part of the directory name. E.g. the first 8 characters of the dagster run ID. If None, a random ID is generated.</p> <code>None</code> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/files.py</code> <pre><code>@staticmethod\ndef mkdir_temp(temp_dir_id: str = None) -&gt; Path:\n    \"\"\"Create a temporary directory with the required permissions.\n\n    The path of the new directory is `/tmp/tmp_3dbag_&lt;temp_dir_id&gt;`.\n\n    Args:\n        temp_dir_id (str): The ID-part of the directory name. E.g. the first 8\n            characters of the dagster run ID. If None, a random ID is generated.\n    \"\"\"\n    if temp_dir_id:\n        dir_id = temp_dir_id\n    else:\n        dir_id = \"\".join(random.choice(string.ascii_letters) for _ in range(8))\n    tmp = Path(make_temp_path(dir_id))\n    tmp.mkdir(exist_ok=True)\n    tmp.chmod(mode=0o777)\n    return tmp\n</code></pre>"},{"location":"reference/bag3d/common/resources/files/#bag3d.common.resources.files.FileStoreResource","title":"<code>FileStoreResource</code>","text":"<p>               Bases: <code>ConfigurableResource</code></p> <p>Location of the data files that are generated in the pipeline. data_dir: The directory where the files are stored. If None, the resource is initialized with a temporary directory.</p> <p>TODO: make the directory functions in .core (bag3d_export_dir etc) members of this</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/files.py</code> <pre><code>class FileStoreResource(ConfigurableResource):\n    \"\"\"Location of the data files that are generated in the pipeline.\n    data_dir: The directory where the files are stored.\n    If None, the resource is initialized with a temporary directory.\n\n    TODO: make the directory functions in .core (bag3d_export_dir etc) members of this\n    \"\"\"\n\n    data_dir: Optional[str] = None\n\n    def __init__(\n        self,\n        data_dir: Optional[Union[Path, str]] = None,\n    ):\n        super().__init__(data_dir=str(data_dir) if data_dir else None)\n\n    @property\n    def file_store(self) -&gt; FileStore:\n        if self.data_dir:\n            return FileStore(data_dir=self.data_dir)\n        else:\n            return FileStore()\n</code></pre>"},{"location":"reference/bag3d/common/resources/version/","title":"version","text":""},{"location":"reference/bag3d/common/resources/version/#bag3d.common.resources.version.VersionResource","title":"<code>VersionResource</code>","text":"<p>               Bases: <code>ConfigurableResource</code></p> <p>A resource for setting up the version release.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/resources/version.py</code> <pre><code>class VersionResource(ConfigurableResource):\n    \"\"\"\n    A resource for setting up the version release.\n    \"\"\"\n\n    version: Optional[str] = None\n\n    def __init__(\n        self,\n        version: Optional[str] = None,\n    ):\n        super().__init__(\n            version=version\n            or \"\".join(random.choice(string.ascii_letters) for _ in range(8))\n        )\n</code></pre>"},{"location":"reference/bag3d/common/resources/wkt/","title":"wkt","text":""},{"location":"reference/bag3d/common/sqlfiles/","title":"sqlfiles","text":"<p>SQL files which are loaded for execution by bag3d.common.utils.database.load_sql. The SQL script can contain parameters in the form of <code>${...}</code>, which is understood by most database managers.</p>"},{"location":"reference/bag3d/common/utils/","title":"utils","text":""},{"location":"reference/bag3d/common/utils/dagster/","title":"dagster","text":"<p>Utilities for working with the dagster instance</p>"},{"location":"reference/bag3d/common/utils/dagster/#bag3d.common.utils.dagster.PartitionDefinition3DBagDistribution","title":"<code>PartitionDefinition3DBagDistribution</code>","text":"<p>               Bases: <code>StaticPartitionsDefinition</code></p> <p>Distribution tiles</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/dagster.py</code> <pre><code>class PartitionDefinition3DBagDistribution(StaticPartitionsDefinition):\n    \"\"\"Distribution tiles\"\"\"\n\n    def __init__(self):\n        logger = get_dagster_logger(\"PartitionDefinition3DBagDistribution\")\n        try:\n            tile_ids = get_export_tile_ids()\n        except BaseException as e:\n            logger.exception(e)\n            tile_ids = []\n        super().__init__(partition_keys=sorted(list(tile_ids)))\n</code></pre>"},{"location":"reference/bag3d/common/utils/dagster/#bag3d.common.utils.dagster.format_date","title":"<code>format_date(input_date, version=True)</code>","text":"<p>Formats a date for using it in versions, filenames, attributes etc.</p> <p>Parameters:</p> Name Type Description Default <code>input_date</code> <code>date</code> required <code>version</code> <code>bool</code> <p>If True, format the input_date as '9999.99.99', else as '9999-99-99'</p> <code>True</code> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/dagster.py</code> <pre><code>def format_date(input_date: date, version: bool = True) -&gt; str:\n    \"\"\"Formats a date for using it in versions, filenames, attributes etc.\n\n    Args:\n        input_date:\n        version: If True, format the input_date as '9999.99.99', else as '9999-99-99'\n    \"\"\"\n    if version:\n        return input_date.strftime(\"%Y.%m.%d\")\n    else:\n        return input_date.strftime(\"%Y-%m-%d\")\n</code></pre>"},{"location":"reference/bag3d/common/utils/dagster/#bag3d.common.utils.dagster.get_run_id","title":"<code>get_run_id(context, short=True)</code>","text":"<p>Return the Run ID from the execution context.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <p>A dagster context object.</p> required <code>short</code> <code>bool</code> <p>Return only the first 8 characters of the ID or the complete ID.</p> <code>True</code> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/dagster.py</code> <pre><code>def get_run_id(context, short=True):\n    \"\"\"Return the Run ID from the execution context.\n\n    Args:\n        context: A dagster context object.\n        short (bool): Return only the first 8 characters of the ID or the complete ID.\n    \"\"\"\n    if context is None:\n        return None\n    if context.dagster_run is None:\n        return None\n    if short:\n        return context.dagster_run.run_id.split(\"-\")[0]\n    else:\n        return context.dagster_run.run_id.split(\"-\")\n</code></pre>"},{"location":"reference/bag3d/common/utils/dagster/#bag3d.common.utils.dagster.get_upstream_data_version","title":"<code>get_upstream_data_version(context, asset_key)</code>","text":"<p>Get the data version of an upstream asset. The upstream asset must be a dependency of the current asset that passes its execution context into this function.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/dagster.py</code> <pre><code>def get_upstream_data_version(\n    context: AssetExecutionContext, asset_key: AssetKey\n) -&gt; str:\n    \"\"\"Get the data version of an upstream asset.\n    The upstream asset must be a dependency of the current asset that passes its\n    execution context into this function.\"\"\"\n    step_execution_context = context.get_step_execution_context()\n    return str(step_execution_context.input_asset_records[asset_key].data_version.value)\n</code></pre>"},{"location":"reference/bag3d/common/utils/database/","title":"database","text":""},{"location":"reference/bag3d/common/utils/database/#bag3d.common.utils.database.create_schema","title":"<code>create_schema(context, new_schema)</code>","text":"<p>CREATE SCHEMA IF NOT EXISTS new_schema</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/database.py</code> <pre><code>def create_schema(context, new_schema):\n    \"\"\"CREATE SCHEMA IF NOT EXISTS new_schema\"\"\"\n    conn = context.resources.db_connection.connect\n    q = SQL(\"CREATE SCHEMA IF NOT EXISTS {sch};\").format(sch=Identifier(new_schema))\n    context.log.info(conn.print_query(q))\n    conn.send_query(q)\n</code></pre>"},{"location":"reference/bag3d/common/utils/database/#bag3d.common.utils.database.drop_table","title":"<code>drop_table(context, new_table)</code>","text":"<p>DROP TABLE IF EXISTS new_table CASCADE</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/database.py</code> <pre><code>def drop_table(context, new_table):\n    \"\"\"DROP TABLE IF EXISTS new_table CASCADE\"\"\"\n    conn = context.resources.db_connection.connect\n    q = SQL(\"DROP TABLE IF EXISTS {tbl} CASCADE;\").format(tbl=new_table.id)\n    context.log.info(conn.print_query(q))\n    conn.send_query(q)\n</code></pre>"},{"location":"reference/bag3d/common/utils/database/#bag3d.common.utils.database.load_sql","title":"<code>load_sql(filename=None, query_params=None)</code>","text":"<p>Load SQL from a file and inject parameters if provided.</p> <p>If providing query parametes, they need to be in a dict, where the keys are the parameter names.</p> <p>The SQL script can contain parameters in the form of <code>${...}</code>, which is understood by most database managers. This is handy for developing the SQL scripts in a database manager, without having to execute the pipeline. However, the python formatting only understands <code>{...}</code> placeholders, so the <code>$</code> are removed from <code>${...}</code> when the SQL is loaded from the file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>SQL File to load (without the path) from the <code>sql</code> sub-package. If None, it will load the <code>.sql</code> file with the name equal to the caller function's name.</p> <code>None</code> <code>query_params</code> <code>dict</code> <p>If provided, the templated SQL is formatted with the parameters.</p> <code>None</code> <p>For example:</p> <p>.. code-block:: python</p> <pre><code>def my_func():\n    load_sql() # loads my_func.sql from bag3d_pipeline.sql\n</code></pre> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/database.py</code> <pre><code>def load_sql(filename: str = None, query_params: dict = None):  # pragma: no cover\n    \"\"\"Load SQL from a file and inject parameters if provided.\n\n    If providing query parametes, they need to be in a dict, where the keys are the\n    parameter names.\n\n    The SQL script can contain parameters in the form of ``${...}``, which is\n    understood by most database managers. This is handy for developing the SQL scripts\n    in a database manager, without having to execute the pipeline.\n    However, the python formatting only understands ``{...}`` placeholders, so the\n    ``$`` are removed from ``${...}`` when the SQL is loaded from the file.\n\n    Args:\n        filename (str): SQL File to load (without the path) from the ``sql``\n            sub-package. If None, it will load the ``.sql`` file with the name equal to\n            the caller function's name.\n        query_params (dict): If provided, the templated SQL is formatted with the\n            parameters.\n\n    For example:\n\n    .. code-block:: python\n\n        def my_func():\n            load_sql() # loads my_func.sql from bag3d_pipeline.sql\n\n    \"\"\"\n    # Find the name of the main package. This should be bag3d.&lt;package&gt;, e.g. bag3d.core\n    stk = inspect.stack()[1]\n    mod = inspect.getmodule(stk[0])\n    pkgs = mod.__package__.split(\".\")\n    if pkgs[0] != \"bag3d\" and len(pkgs) &lt; 2:\n        raise RuntimeError(\n            \"Trying to load SQL files from a namspace that is not bag3d.&lt;package&gt;.\"\n        )\n    sqlfiles_module = \".\".join([pkgs[0], pkgs[1], \"sqlfiles\"])\n    # Get the name of the calling function\n    _f = filename if filename is not None else f\"{inspect.stack()[1].function}.sql\"\n    _sql = resources.files(sqlfiles_module).joinpath(_f).read_text()\n    _pysql = _sql.replace(\"${\", \"{\")\n    return inject_parameters(_pysql, query_params)\n</code></pre>"},{"location":"reference/bag3d/common/utils/database/#bag3d.common.utils.database.table_exists","title":"<code>table_exists(context, table)</code>","text":"<p>CHECKS IF TABLE EXISTS</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/database.py</code> <pre><code>def table_exists(context, table) -&gt; bool:\n    \"\"\"CHECKS IF TABLE EXISTS\"\"\"\n    query = SQL(\"\"\"SELECT EXISTS (\n                   SELECT FROM \n                        pg_tables\n                   WHERE \n                        schemaname = {schema} AND \n                        tablename  = {table}\n                    );\"\"\").format(schema=table.schema.str, table=table.table.str)\n    res = context.resources.db_connection.connect.get_dict(query)\n    return res[0][\"exists\"]\n</code></pre>"},{"location":"reference/bag3d/common/utils/files/","title":"files","text":"<p>Working with file inputs and outputs</p>"},{"location":"reference/bag3d/common/utils/files/#bag3d.common.utils.files.BadArchiveError","title":"<code>BadArchiveError</code>","text":"<p>               Bases: <code>OSError</code></p> <p>The archive contains a bad file</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/files.py</code> <pre><code>class BadArchiveError(OSError):\n    \"\"\"The archive contains a bad file\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/bag3d/common/utils/files/#bag3d.common.utils.files.bag3d_dir","title":"<code>bag3d_dir(root_dir)</code>","text":"<p>The 3D BAG data directory</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/files.py</code> <pre><code>def bag3d_dir(root_dir: os.PathLike) -&gt; Path:\n    \"\"\"The 3D BAG data directory\"\"\"\n    return Path(root_dir) / \"3DBAG\"\n</code></pre>"},{"location":"reference/bag3d/common/utils/files/#bag3d.common.utils.files.bag3d_export_dir","title":"<code>bag3d_export_dir(root_dir, version)</code>","text":"<p>Create the 3DBAG export directory if does not exist</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/files.py</code> <pre><code>def bag3d_export_dir(root_dir: os.PathLike, version: str) -&gt; Path:\n    \"\"\"Create the 3DBAG export directory if does not exist\"\"\"\n    export_dir = bag3d_dir(root_dir) / f\"export_{version}\"\n    export_dir.mkdir(exist_ok=True, parents=True)\n    return export_dir\n</code></pre>"},{"location":"reference/bag3d/common/utils/files/#bag3d.common.utils.files.check_export_results","title":"<code>check_export_results(path_quadtree_tsv, path_tiles_dir)</code>","text":"<p>Parse the <code>quadtree.tsv</code> written by tyler, check if all formats exists for each tile, add the tile WKT.</p> <p>Returns:</p> Type Description <code>Iterator[ExportResult]</code> <p>Generator of ExportResult</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/files.py</code> <pre><code>def check_export_results(\n    path_quadtree_tsv: Path, path_tiles_dir: Path\n) -&gt; Iterator[ExportResult]:\n    \"\"\"Parse the `quadtree.tsv` written by *tyler*, check if all formats exists for each\n    tile, add the tile WKT.\n\n    Returns:\n         Generator of ExportResult\n    \"\"\"\n    with path_quadtree_tsv.open(\"r\") as fo:\n        csvreader = csv.DictReader(fo, delimiter=\"\\t\")\n        for row in csvreader:\n            if row[\"leaf\"] == \"true\" and int(row[\"nr_items\"]) &gt; 0:\n                leaf_id = row[\"id\"]\n                leaf_id_in_filename = leaf_id.replace(\"/\", \"-\")\n                leaf_dir = path_tiles_dir.joinpath(leaf_id)\n                if leaf_dir.exists():\n                    obj_paths = tuple(\n                        p for p in leaf_dir.iterdir() if p.suffix == \".obj\"\n                    )\n                    basename = path_tiles_dir.joinpath(leaf_id, leaf_id_in_filename)\n                    yield ExportResult(\n                        tile_id=leaf_id,\n                        cityjson_path=basename.with_suffix(\".city.json\"),\n                        gpkg_path=basename.with_suffix(\".gpkg\"),\n                        obj_paths=obj_paths,\n                        wkt=row[\"wkt\"],\n                    )\n</code></pre>"},{"location":"reference/bag3d/common/utils/files/#bag3d.common.utils.files.geoflow_crop_dir","title":"<code>geoflow_crop_dir(root_dir)</code>","text":"<p>Directory for the Geoflow crop-reconstruct output</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/files.py</code> <pre><code>def geoflow_crop_dir(root_dir: os.PathLike) -&gt; Path:\n    \"\"\"Directory for the Geoflow crop-reconstruct output\"\"\"\n    return bag3d_dir(root_dir) / \"crop_reconstruct\"\n</code></pre>"},{"location":"reference/bag3d/common/utils/files/#bag3d.common.utils.files.get_export_tile_ids","title":"<code>get_export_tile_ids()</code>","text":"<p>Get the IDs of the distribution tiles from the file system. It reads the <code>quadtree.tsv</code> output from tyler and extracts the IDs of the leaf tiles.</p> <p>Returns:</p> Type Description <code>Sequence[str]</code> <p>List of tile IDs</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/files.py</code> <pre><code>def get_export_tile_ids() -&gt; Sequence[str]:\n    \"\"\"Get the IDs of the distribution tiles from the file system.\n    It reads the `quadtree.tsv` output from *tyler* and extracts the IDs of the\n    leaf tiles.\n\n    Returns:\n        List of tile IDs\n    \"\"\"\n    tileids = []\n\n    env = os.getenv(\"DAGSTER_ENVIRONMENT\", \"test\")\n    if env == \"test\":\n        root_dir = Path(os.getenv(\"BAG3D_FILESTORE\")) / \"reconstruction_input\"\n        version = \"test_version\"\n    else:\n        root_dir = Path(os.getenv(\"BAG3D_FILESTORE\", \"/data\"))\n        version = os.getenv(\"BAG3D_RELEASE_VERSION\", \"test_version\")\n\n    export_dir = bag3d_export_dir(root_dir=root_dir, version=version)\n\n    path_tiles_dir = export_dir.joinpath(\"tiles\")\n    path_quadtree_tsv = export_dir.joinpath(\"quadtree.tsv\")\n    if path_quadtree_tsv.exists():\n        tileids = [\n            er.tile_id for er in check_export_results(path_quadtree_tsv, path_tiles_dir)\n        ]\n    else:\n        raise FileNotFoundError(f\"File not found: {path_quadtree_tsv}\")\n\n    return tileids\n</code></pre>"},{"location":"reference/bag3d/common/utils/files/#bag3d.common.utils.files.unzip","title":"<code>unzip(file, dest, remove=True)</code>","text":"<p>Uncompress the whole zip archive and optionally delete the zip.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>Path</code> <p>The Path to the zip.</p> required <code>dest</code> <code>Path</code> <p>The Path to the destination directory.</p> required <code>remove</code> <code>bool</code> <p>Whether to remove the zip.</p> <code>True</code> <p>Raises:</p> Type Description <code>BadArchiveError</code> <p>The archive contains at least one bad file</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/files.py</code> <pre><code>def unzip(file: Path, dest: Path, remove: bool = True) -&gt; None:\n    \"\"\"Uncompress the whole zip archive and optionally delete the zip.\n\n    Args:\n        file: The Path to the zip.\n        dest: The Path to the destination directory.\n        remove: Whether to remove the zip.\n\n    Raises:\n        BadArchiveError: The archive contains at least one bad file\n    \"\"\"\n    logger = get_dagster_logger()\n    logger.info(f\"Uncompressing {file} to {dest}\")\n    with ZipFile(file, \"r\") as ezip:\n        first_bad_file = ezip.testzip()\n        if first_bad_file:\n            raise BadArchiveError(\n                f\"The archive contains at least one bad file: {first_bad_file}\"\n            )\n        ezip.extractall(path=dest)\n    if remove:\n        logger.info(f\"Deleting {file}\")\n        file.unlink()\n</code></pre>"},{"location":"reference/bag3d/common/utils/geodata/","title":"geodata","text":""},{"location":"reference/bag3d/common/utils/geodata/#bag3d.common.utils.geodata.add_info","title":"<code>add_info(metadata, info)</code>","text":"<p>Add the :py:func:<code>ogrinfo</code> output to the metadata returned by :py:func:<code>download_extract</code>.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>dict</code> <p>Metadata returned by :py:func:<code>download_extract</code>.</p> required <code>info</code> <code>dict</code> <p>:py:func:<code>ogrinfo</code> output.</p> required Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/geodata.py</code> <pre><code>def add_info(metadata: dict, info: dict) -&gt; None:\n    \"\"\"Add the :py:func:`ogrinfo` output to the metadata returned by\n    :py:func:`download_extract`.\n\n    Args:\n        metadata: Metadata returned by :py:func:`download_extract`.\n        info: :py:func:`ogrinfo` output.\n    \"\"\"\n    for layername, layerinfo in info.items():\n        layer = layername.lower()\n        metadata.update(layerinfo)\n        for dt, ft in metadata[\"timeliness\"].items():\n            if layer in ft:\n                metadata[f\"Timeliness [{layer}]\"] = dt\n    del metadata[\"timeliness\"]\n</code></pre>"},{"location":"reference/bag3d/common/utils/geodata/#bag3d.common.utils.geodata.attributes_dict","title":"<code>attributes_dict(attributes_str)</code>","text":"<p>[     {     \"name\": attribute name,     \"type\": value type,     \"constraints\" value constraints     }, ... ]</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/geodata.py</code> <pre><code>def attributes_dict(attributes_str: str) -&gt; List[dict]:\n    \"\"\"\n    [\n        {\n        \"name\": attribute name,\n        \"type\": value type,\n        \"constraints\" value constraints\n        },\n    ...\n    ]\n    \"\"\"\n    ret = []\n    _astr = attributes_str.strip(\"\\n\").strip().split(\"\\n\")\n    for i in _astr:\n        adict = {}\n        aname, specs = i.split(\":\")\n        try:\n            # 'String (0.0) NOT NULL'\n            atype, contstraints = specs.strip().split(\")\")\n        except ValueError:\n            # 'inOnderzoek: Integer(Boolean) (0.0)'\n            atype, contstraints = specs.strip(), \"\"\n        adict[\"name\"] = aname\n        adict[\"type\"] = atype + \")\"\n        if contstraints == \"\":\n            adict[\"constraints\"] = None\n        else:\n            adict[\"constraints\"] = TableColumnConstraints(\n                other=[\n                    contstraints.strip(),\n                ]\n            )\n        ret.append(adict)\n    return ret\n</code></pre>"},{"location":"reference/bag3d/common/utils/geodata/#bag3d.common.utils.geodata.bbox_from_wkt","title":"<code>bbox_from_wkt(wkt)</code>","text":"<p>Returns the BBOX of a WKT Polygon.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/geodata.py</code> <pre><code>def bbox_from_wkt(wkt):\n    \"\"\"Returns the BBOX of a WKT Polygon.\"\"\"\n    re_polygon = re.compile(r\"(?&lt;=polygon).*\", re.IGNORECASE)\n    m = re_polygon.search(wkt)\n    if m:\n        ext = m.group().strip().strip(\"(\").strip(\")\").split(\")\")[0]\n        cstr = ext.split(\",\")\n        fcoord = tuple(map(float, cstr[0].strip(\" \").split(\" \")))\n        minx, miny = fcoord\n        maxx, maxy = fcoord\n        for coord in cstr:\n            x, y = tuple(map(float, coord.strip(\" \").split(\" \")))\n            minx = x if x &lt; minx else minx\n            miny = y if y &lt; miny else miny\n            maxx = x if x &gt; maxx else maxx\n            maxy = y if y &gt; maxy else maxy\n        return minx, miny, maxx, maxy\n    else:\n        return None\n</code></pre>"},{"location":"reference/bag3d/common/utils/geodata/#bag3d.common.utils.geodata.ogr2postgres","title":"<code>ogr2postgres(context, dataset, extract_path, feature_type, xsd, new_table)</code>","text":"<p>ogr2ogr a layer from zipped data extract from GML into Postgres.</p> <p>It was developed for loading the TOP10NL and BGT extracts that are downloaded from the PDOK API.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>OpExecutionContext</code> <p>Op execution context from Dagster.</p> required <code>dataset</code> <code>str</code> <p>Name of the dataset ('top10nl', 'bgt').</p> required <code>extract_path</code> <code>Path</code> <p>Local path to the zipped extract.</p> required <code>feature_type</code> <code>str</code> <p>The feature layer to load from the <code>dataset</code></p> required <code>xsd</code> <code>str</code> <p>Path (URL) to the XSD file.</p> required <code>new_table</code> <code>PostgresTableIdentifier</code> <p>The name of the new Postgres table to load the data into.</p> required <p>Returns:     Runs :py:func:<code>postgrestable_metadata</code> on return and returns a dict of metadata     of the <code>new_table</code> loaded with data.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/geodata.py</code> <pre><code>def ogr2postgres(\n    context: OpExecutionContext,\n    dataset: str,\n    extract_path: Path,\n    feature_type: str,\n    xsd: str,\n    new_table: PostgresTableIdentifier,\n) -&gt; dict:\n    \"\"\"ogr2ogr a layer from zipped data extract from GML into Postgres.\n\n    It was developed for loading the TOP10NL and BGT extracts that are downloaded from\n    the PDOK API.\n\n    Args:\n        context: Op execution context from Dagster.\n        dataset: Name of the dataset ('top10nl', 'bgt').\n        extract_path: Local path to the zipped extract.\n        feature_type: The feature layer to load from the ``dataset``\n        xsd: Path (URL) to the XSD file.\n        new_table: The name of the new Postgres table to load the data into.\n    Returns:\n        Runs :py:func:`postgrestable_metadata` on return and returns a dict of metadata\n        of the ``new_table`` loaded with data.\n    \"\"\"\n    gdal = context.resources.gdal.app\n    dsn = context.resources.db_connection.connect.dsn\n\n    cmd = \" \".join(\n        [\n            \"{exe}\",\n            \"--config PG_USE_COPY=YES\",\n            \"-overwrite\",\n            \"-nln {new_table}\",\n            '-oo XSD=\"{xsd}\"',\n            \"-oo WRITE_GFS=NO\",\n            \"-lco UNLOGGED=ON\",\n            \"-lco SPATIAL_INDEX=NONE\",\n            \"-lco GEOMETRY_NAME=wkb_geometry\",\n            '-f PostgreSQL PG:\"{dsn}\"',\n            \"/vsizip/{local_path}/{dataset}_{feature_type}.gml {feature_type}\",\n        ]\n    )\n\n    kwargs = {\n        \"new_table\": new_table,\n        \"feature_type\": feature_type,\n        \"dsn\": dsn,\n        \"xsd\": xsd,\n        \"dataset\": dataset,\n    }\n    return_code, output = gdal.execute(\n        \"ogr2ogr\", command=cmd, kwargs=kwargs, local_path=extract_path\n    )\n    if return_code == 0:\n        return postgrestable_metadata(context, new_table)\n</code></pre>"},{"location":"reference/bag3d/common/utils/geodata/#bag3d.common.utils.geodata.ogrinfo","title":"<code>ogrinfo(context, dataset, extract_path, feature_types, xsd)</code>","text":"<p>Runs ogrinfo on the zipped extract.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/geodata.py</code> <pre><code>def ogrinfo(\n    context: OpExecutionContext,\n    dataset: str,\n    extract_path: Path,\n    feature_types: list,\n    xsd: str,\n):\n    \"\"\"Runs ogrinfo on the zipped extract.\"\"\"\n    gdal = context.resources.gdal.app\n    cmd = \" \".join(\n        [\n            \"{exe}\",\n            \"-so\",\n            \"-al\",\n            '-oo XSD=\"{xsd}\"',\n            \"-oo WRITE_GFS=NO\",\n            \"/vsizip/{local_path}/{dataset}_{feature_type}.gml {feature_type}\",\n        ]\n    )\n\n    info = {}\n    for feature_type in feature_types:\n        kwargs = {\"xsd\": xsd, \"dataset\": dataset, \"feature_type\": feature_type}\n        return_code, output = gdal.execute(\n            \"ogrinfo\", command=cmd, kwargs=kwargs, local_path=extract_path\n        )\n        if return_code == 0:\n            layername, layerinfo = parse_ogrinfo(output, feature_type)\n            info[str(layername)] = layerinfo\n    return info\n</code></pre>"},{"location":"reference/bag3d/common/utils/geodata/#bag3d.common.utils.geodata.parse_ogrinfo","title":"<code>parse_ogrinfo(ogrinfo_stdout, feature_type)</code>","text":"<p>Parses the stdout of ogrinfo into a dictionary.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/geodata.py</code> <pre><code>def parse_ogrinfo(ogrinfo_stdout: str, feature_type: str) -&gt; (str, dict):\n    \"\"\"Parses the stdout of ogrinfo into a dictionary.\"\"\"\n    layerinfo = {}\n    inf = ogrinfo_stdout.split(\"Layer name: \")[1]\n    layername = inf.split(\"\\n\")[0].lower()\n    if layername != feature_type:\n        raise ValueError(\n            f\"Encountered a {layername} layer, but expected {feature_type}\"\n        )\n\n    re_feature_count = re.compile(r\"(?&lt;=Feature Count: )\\d+\")\n    ft = feature_type.lower()\n    layerinfo[f\"Feature Count [{ft}]\"] = int(re_feature_count.search(inf)[0])\n    layerinfo[f\"Extent [{ft}]\"] = dict(\n        (geom, wkt) for geom, wkt in parse_ogrinfo_extent(inf)\n    )\n    schema = parse_ogrinfo_attributes(inf[inf.find(\"gml_id\") :])\n    layerinfo[f\"Schema [{ft}]\"] = TableSchemaMetadataValue(schema)\n    return layername, layerinfo\n</code></pre>"},{"location":"reference/bag3d/common/utils/geodata/#bag3d.common.utils.geodata.parse_ogrinfo_attributes","title":"<code>parse_ogrinfo_attributes(attributes_str)</code>","text":"<p>Parses the attributes list of the ogrinfo stdout into a :py:class:<code>TableSchema</code></p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/geodata.py</code> <pre><code>def parse_ogrinfo_attributes(attributes_str: str) -&gt; TableSchema:\n    \"\"\"Parses the attributes list of the ogrinfo stdout into a :py:class:`TableSchema`\"\"\"\n    alist = attributes_dict(attributes_str)\n    schema = attributes_schema(alist)\n    return schema\n</code></pre>"},{"location":"reference/bag3d/common/utils/geodata/#bag3d.common.utils.geodata.pdal_info","title":"<code>pdal_info(pdal, file_path, with_all=False)</code>","text":"<p>Run 'pdal info' on a point cloud file.</p> <p>Parameters:</p> Name Type Description Default <code>pdal</code> <code>AppImage</code> <p>The pdal AppImage executable.</p> required <code>file_path</code> <code>Path</code> <p>Path to the point cloud file.</p> required <code>with_all</code> <code>bool</code> <p>If true, run <code>pdal info --all</code>, else run <code>pdal info --metadata</code>. Defaults to <code>False</code>.</p> <code>False</code> <p>Returns:     A tuple of (pdal's return code, parsed pdal info output)</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/geodata.py</code> <pre><code>def pdal_info(\n    pdal: AppImage, file_path: Path, with_all: bool = False\n) -&gt; Tuple[int, dict]:\n    \"\"\"Run 'pdal info' on a point cloud file.\n\n    Args:\n        pdal (AppImage): The pdal AppImage executable.\n        file_path: Path to the point cloud file.\n        with_all: If true, run ``pdal info --all``, else run ``pdal info --metadata``.\n            Defaults to ``False``.\n    Returns:\n        A tuple of (pdal's return code, parsed pdal info output)\n    \"\"\"\n    cmd_list = [\n        \"{exe}\",\n        \"info\",\n    ]\n    cmd_list.append(\"--all\") if with_all else cmd_list.append(\"--metadata\")\n    cmd_list.append(\"{local_path}\")\n    return_code, output = pdal.execute(\n        \"pdal\", command=\" \".join(cmd_list), local_path=file_path\n    )\n\n    return return_code, json.loads(output)\n</code></pre>"},{"location":"reference/bag3d/common/utils/requests/","title":"requests","text":""},{"location":"reference/bag3d/common/utils/requests/#bag3d.common.utils.requests.download_as_str","title":"<code>download_as_str(url, parameters=None)</code>","text":"<p>Download a file as string in memory.</p> <p>Returns:</p> Type Description <code>str</code> <p>The downloaded package as string.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/requests.py</code> <pre><code>def download_as_str(url: str, parameters: Mapping = None) -&gt; str:\n    \"\"\"Download a file as string in memory.\n\n    Returns:\n         The downloaded package as string.\n    \"\"\"\n    resp = requests.get(url=url, params=parameters, verify=True)\n    if resp.status_code == 200:\n        return resp.text\n    else:  # pragma: no cover\n        raise ValueError(\n            f\"Failed to download JSON. HTTP Status {resp.status_code} for {resp.url}\"\n        )\n</code></pre>"},{"location":"reference/bag3d/common/utils/requests/#bag3d.common.utils.requests.download_file","title":"<code>download_file(url, target_path, chunk_size=1024, parameters=None, verify=True)</code>","text":"<p>Download a large file and save it to disk.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the file to be downloaded.</p> required <code>target_path</code> <code>Path</code> <p>Path to the target file or directory. If <code>save_path</code> is a directory, then the target file name is the last part of the <code>url</code>.</p> required <code>chunk_size</code> <code>int</code> <p>The <code>chunk_size</code> parameter passed to :py:func:`request.Response.iter_content. Defaults to <code>1024</code>.</p> <code>1024</code> <code>parameters</code> <code>dict</code> <p>Query parameters passed to :py:func:<code>requests.get</code>.</p> <code>None</code> <code>verify</code> <code>bool</code> <p>Whether to verify SSL certificate.</p> <code>True</code> <p>Returns:     The local Path to the downloaded file, or None on failure</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/requests.py</code> <pre><code>def download_file(\n    url: str,\n    target_path: Path,\n    chunk_size: int = 1024,\n    parameters: Mapping = None,\n    verify: bool = True,\n) -&gt; Union[Path, None]:\n    \"\"\"Download a large file and save it to disk.\n\n    Args:\n        url (str): The URL of the file to be downloaded.\n        target_path (Path): Path to the target file or directory. If ``save_path`` is a\n            directory, then the target file name is the last part of the ``url``.\n        chunk_size (int): The ``chunk_size`` parameter passed to\n            :py:func:`request.Response.iter_content. Defaults to ``1024``.\n        parameters (dict): Query parameters passed to :py:func:`requests.get`.\n        verify (bool): Whether to verify SSL certificate.\n    Returns:\n        The local Path to the downloaded file, or None on failure\n    \"\"\"\n    logger = get_dagster_logger()\n    if target_path.is_dir():\n        local_filename = url.split(\"/\")[-1]\n        fpath = target_path / local_filename\n    else:\n        fpath = target_path\n    logger.info(f\"Downloading from {url} to {fpath}\")\n    session = requests.Session()  # https://stackoverflow.com/a/63417213\n\n    try:\n        r = session.get(url, params=parameters, stream=True, verify=verify)\n        if r.ok:\n            with fpath.open(\"wb\") as fd:\n                for chunk in r.iter_content(chunk_size=chunk_size):\n                    fd.write(chunk)\n            return fpath\n        else:  # pragma: no cover\n            r.raise_for_status()\n        r.close()\n    except (\n        requests.exceptions.BaseHTTPError,\n        requests.exceptions.HTTPError,\n    ) as e:  # pragma: no cover\n        logger.exception(e)\n        return None\n</code></pre>"},{"location":"reference/bag3d/common/utils/requests/#bag3d.common.utils.requests.get_extract_download_link","title":"<code>get_extract_download_link(url, featuretypes, data_format, geofilter)</code>","text":"<p>Request an export and download link from the API.</p> Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/requests.py</code> <pre><code>def get_extract_download_link(url, featuretypes, data_format, geofilter) -&gt; str:\n    \"\"\"Request an export and download link from the API.\"\"\"\n    logger = get_dagster_logger()\n    request_json = {\n        \"featuretypes\": featuretypes,\n        \"format\": data_format,\n    }\n    if geofilter is not None:\n        request_json[\"geofilter\"] = geofilter\n    r_post = requests.post(url, json=request_json)\n    logger.info(f\"Requesting extract: {r_post.url} with {request_json} \")\n    if not r_post.status_code == requests.codes.accepted:  # pragma: no cover\n        logger.error(r_post.text)\n        r_post.raise_for_status()\n    else:\n        _u = urlparse(url)\n        pdok_server = f\"{_u.scheme}://{_u.hostname}/\"\n        url_status = urljoin(pdok_server, r_post.json()[\"_links\"][\"status\"][\"href\"])\n        url_download = None\n\n        if requests.get(url_status, verify=True).status_code == requests.codes.ok:\n            while (\n                r_status := requests.get(url_status, verify=True)\n            ).status_code == requests.codes.ok:\n                sleep(15)\n            if not r_status.status_code == requests.codes.created:  # pragma: no cover\n                logger.error(r_status.text)\n                r_status.raise_for_status()\n            url_download = urljoin(\n                pdok_server, r_status.json()[\"_links\"][\"download\"][\"href\"]\n            )\n        elif (\n            requests.get(url_status, verify=True).status_code == requests.codes.created\n        ):\n            r_status = requests.get(url_status, verify=True)\n            url_download = urljoin(\n                pdok_server, r_status.json()[\"_links\"][\"download\"][\"href\"]\n            )\n        else:  # pragma: no cover\n            _r = requests.get(url_status, verify=True)\n            logger.error(_r.text)\n            _r.raise_for_status()\n        logger.info(f\"Extract URL: {url_download}\")\n        return url_download\n</code></pre>"},{"location":"reference/bag3d/common/utils/requests/#bag3d.common.utils.requests.get_metadata","title":"<code>get_metadata(url_api)</code>","text":"<p>Get metadata from a PDOK API.</p> <p>:returns: {\"timeliness\": : [featuretype,...]} Source code in <code>.venv/lib/python3.13/site-packages/bag3d/common/utils/requests.py</code> <pre><code>def get_metadata(url_api: str):\n    \"\"\"Get metadata from a PDOK API.\n\n    :returns: {\"timeliness\": &lt;date&gt;: [featuretype,...]}\n    \"\"\"\n    r_meta = requests.get(url_api, verify=True)\n    if not r_meta.status_code == requests.codes.ok:  # pragma: no cover\n        r_meta.raise_for_status()\n    meta = {\"timeliness\": {}}\n    for layer in r_meta.json()[\"timeliness\"]:\n        if layer[\"datetimeTo\"][-1] == \"Z\":\n            dt = str(datetime.fromisoformat(layer[\"datetimeTo\"][:-1]).date())\n        else:  # pragma: no cover\n            dt = str(datetime.fromisoformat(layer[\"datetimeTo\"]).date())\n        if dt in meta[\"timeliness\"]:\n            meta[\"timeliness\"][dt].append(layer[\"featuretype\"])\n        else:\n            meta[\"timeliness\"][dt] = [\n                layer[\"featuretype\"],\n            ]\n    return meta\n</code></pre>"}]}